{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882ed062",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "# -*- coding: utf-8 -*-\n",
    "# @Time    : 2022/1/4 14:27\n",
    "# @Author  : hit-itnlp-fengmq\n",
    "# @FileName: T5.py\n",
    "# @Software: PyCharm\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from sentence_transformers import util, SentenceTransformer\n",
    "from torch.utils.data import Dataset, DataLoader,random_split, RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Adafactor, get_linear_schedule_with_warmup\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "\n",
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "setup_seed(2022)\n",
    "\n",
    "def train_summary(data):\n",
    "    pd.set_option('precision', 2)\n",
    "    df_stats = pd.DataFrame(data)\n",
    "    df_stats = df_stats.set_index('epoch')\n",
    "    df_stats.to_csv('train_summary.csv', sep='\\t')\n",
    "    \n",
    "# 加载模型\n",
    "def get_premodel(path=r\"D:\\Anaconda\\learn\\_Bert\\pre_train_model\\t5-small\"):\n",
    "    '''\n",
    "    :param path: 预训练模型在本机的路径\n",
    "    :return:\n",
    "    '''\n",
    "    tokenizer = T5Tokenizer.from_pretrained(path)\n",
    "    model = T5ForConditionalGeneration.from_pretrained(path)\n",
    "    print(\"model load end!\")\n",
    "    return model, tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b44d59ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(Dataset):  # 需要继承data.Dataset\n",
    "    def __init__(self, data_text, data_qa,tokenizer):\n",
    "        self.data_text = data_text\n",
    "        self.data_qa = data_qa\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.max_source_length = 1024\n",
    "        self.max_target_length = 64\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.data_qa[index]\n",
    "        question = item['question']\n",
    "        answer = item['answer']\n",
    "        doc_id = item['doc_id'].strip()\n",
    "        \n",
    "        texts = self.data_text[doc_id]\n",
    "        text = \"\".join(texts)\n",
    "        \n",
    "        q_text = question + \" : \" + text\n",
    "        source_encoding = self.tokenizer.encode_plus(q_text,\n",
    "                                                     add_special_tokens=True,\n",
    "                                                     max_length=self.max_source_length,\n",
    "                                                     padding='max_length',\n",
    "                                                     return_attention_mask=True,\n",
    "                                                     return_tensors='pt',\n",
    "                                                     truncation=True)\n",
    "        input_ids, attention_mask = source_encoding['input_ids'], source_encoding['attention_mask']\n",
    "        # 答案\n",
    "        target_encoding = self.tokenizer.encode_plus(answer,\n",
    "                                                     add_special_tokens=True,\n",
    "                                                     max_length=self.max_target_length,\n",
    "                                                     padding='max_length',\n",
    "                                                     return_attention_mask=True,\n",
    "                                                     truncation=True)\n",
    "        labels = target_encoding.input_ids\n",
    "        labels = [(label if label != self.tokenizer.pad_token_id else -100) for label in labels]\n",
    "        labels = torch.tensor(labels)\n",
    "\n",
    "        return input_ids.squeeze(), attention_mask.squeeze(), labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2cc3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(tokenizer):\n",
    "    data_text  = json.load(open(\"train3.json\",'r',encoding='utf-8'))\n",
    "    data_qa  = json.load(open(\"train_qa2.json\",'r',encoding='utf-8'))\n",
    "    dataset = myDataset(data_text,data_qa,tokenizer)\n",
    "\n",
    "\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    batch_size = 4\n",
    "    train_dataloader = DataLoader(\n",
    "                train_dataset,  # The training samples.\n",
    "                sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "                batch_size = batch_size\n",
    "            )\n",
    "    validation_dataloader = DataLoader(\n",
    "                val_dataset,\n",
    "                sampler = SequentialSampler(val_dataset),\n",
    "                batch_size = batch_size\n",
    "            )\n",
    "    print(\"dataloader load end!\")\n",
    "    return train_dataloader,validation_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0740f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, tokenizer, train_dataloader, validation_dataloader, epochs=5):\n",
    "    training_logs = []\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else'cpu')# \n",
    "    model.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    optimizer = Adafactor(model.parameters(),\n",
    "                          lr=2e-4,\n",
    "                          eps=(1e-30, 1e-3),\n",
    "                          clip_threshold=1.0,\n",
    "                          decay_rate=-0.8,\n",
    "                          beta1=None,\n",
    "                          weight_decay=0.0,\n",
    "                          relative_step=False,\n",
    "                          scale_parameter=False,\n",
    "                          warmup_init=False)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=400, num_training_steps=len(train_dataloader) * epochs)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for data in tqdm(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            data = tuple(t.to(device) for t in data)\n",
    "            input_ids, attention_mask, labels = data\n",
    "            output = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "            loss = output.loss.mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "            break\n",
    "\n",
    "\n",
    "        if epoch >= 2:\n",
    "            s_path = r\"/home/mqfeng/code/mytest/save\"\n",
    "            sub_path = os.path.join(s_path, \"model\" + str(epoch))\n",
    "            os.mkdir(sub_path)\n",
    "            if torch.cuda.device_count() > 1:\n",
    "                model.module.save_pretrained(sub_path)\n",
    "            else:\n",
    "                model.save_pretrained(sub_path)\n",
    "                \n",
    "                \n",
    "        model.eval()\n",
    "        test_loss = []\n",
    "        test_acc = []\n",
    "        with torch.no_grad():\n",
    "            for data in tqdm(validation_dataloader):\n",
    "                data = tuple(t.to(device) for t in data)\n",
    "                input_ids, attention_mask, labels = data\n",
    "                if torch.cuda.device_count() > 1:\n",
    "                    outputs = model.module.generate(input_ids)\n",
    "                else:\n",
    "                    outputs = model.generate(input_ids)\n",
    "                output_all = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "                test_loss.append(output_all.loss.mean().cpu())\n",
    "\n",
    "                labels = [[i.item() for i in label if i != -100] for label in labels]\n",
    "                decode_labels = tokenizer.decode(labels[0], skip_special_tokens=True)\n",
    "                decode_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                if decode_labels == decode_output:\n",
    "                    test_acc.append(1)\n",
    "                else:\n",
    "                    test_acc.append(0)\n",
    "                break\n",
    "        print(\"{}  Train_loss: {}----Test_loss:{} Test_acc:{}\".format(epoch,np.mean(train_loss), np.mean(test_loss),np.mean(test_acc)))\n",
    "        training_logs.append(\n",
    "            {\n",
    "                'epoch': epoch + 1,\n",
    "                'Training Loss': np.mean(train_loss),\n",
    "\n",
    "\n",
    "                'Valid. Loss': np.mean(test_loss),\n",
    "                'Valid. Acc': np.mean(test_acc),\n",
    "            }\n",
    "        )\n",
    "    return training_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df043222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model load end!\n",
      "dataloader load end!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/9494 [00:09<?, ?it/s]\n",
      "  0%|                                                                                         | 0/2374 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Train_loss: 9.167595863342285----Test_loss:5.7501068115234375 Test_acc:0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/9494 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8248/3621006237.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_premodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtraining_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtrain_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8248/2487460358.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, tokenizer, train_dataloader, validation_dataloader, epochs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, tokenizer = get_premodel()\n",
    "train_dataloader,validation_dataloader = get_dataloader(tokenizer)\n",
    "training_logs = train(model, tokenizer, train_dataloader, validation_dataloader)\n",
    "train_summary(training_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad440bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd301d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
