{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01dc5dc3",
   "metadata": {},
   "source": [
    "# extract type 0 data only\n",
    "## and removed answers with magnitude more than 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3424be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def extract_id(start_token='0', filepath=r'alldata.json'):\n",
    "    start = start_token\n",
    "    texts = []\n",
    "    with open(filepath,\"r\",encoding='utf-8') as f:\n",
    "        data=json.load(f)\n",
    "    for key,item in data.items():\n",
    "        questions=item['question']\n",
    "        for q in questions:\n",
    "            q_temp,a=q.split('     ')\n",
    "            idx,q = q_temp.split(\"=\")\n",
    "            idx_=idx.split(\" \")[-2]\n",
    "            if idx_.startswith(start) and int(a)<=3:\n",
    "                text={}\n",
    "                text['q_id']=idx_\n",
    "                text['question']=q.strip()\n",
    "                text['answer']=a\n",
    "                text['doc_id']=key.strip()\n",
    "                texts.append(text)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c816a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract type 0 qa pairs\n",
    "fp = '/Users/rickzhai/Documents/GitHub/ITNLP_Semeval2022_Task6/allqapairs.json'\n",
    "t = extract_id(start_token='0', filepath=fp)\n",
    "write = open(\"qa_0.json\", \"w\", encoding=\"utf-8\")\n",
    "json.dump(t, write, ensure_ascii=False, indent=4)\n",
    "write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3598867",
   "metadata": {},
   "source": [
    "# create df as type_0 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3544f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "qa = r\"/Users/rickzhai/Documents/GitHub/ITNLP_Semeval2022_Task6/number_reasoning/qa_0.json\"\n",
    "recipe = r\"/Users/rickzhai/Documents/GitHub/ITNLP_Semeval2022_Task6/number_reasoning/padded_text_0_1.json\"\n",
    "with open(qa,\"r\",encoding='utf-8') as f:\n",
    "    qa_0=json.load(f)\n",
    "with open(recipe,\"r\",encoding='utf-8') as f:\n",
    "    c=json.load(f)\n",
    "data = {}\n",
    "data['question'] = []\n",
    "data['answer'] = []\n",
    "data['context'] = []\n",
    "for _ in qa_0:\n",
    "    if _.get('question').startswith('How many actions does it take') or _.get('question').startswith('How many times'):\n",
    "        data['question'].append(_.get('question'))\n",
    "        data['answer'].append(int(_.get('answer')))\n",
    "        docid = _.get('doc_id')\n",
    "        the_doc = next((sub for sub in c if sub['doc_id'] == docid), None)\n",
    "        context = ''.join(the_doc['text'])\n",
    "        data['context'].append(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2612906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ca817",
   "metadata": {},
   "source": [
    "# write to csv for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d541e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "#df.to_csv('qa_0.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "863baace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               question  answer  \\\n",
      "0     How many actions does it take to process the m...       1   \n",
      "1     How many actions does it take to process the m...       1   \n",
      "2     How many actions does it take to process the o...       1   \n",
      "3     How many actions does it take to process the b...       2   \n",
      "4     How many actions does it take to process the w...       1   \n",
      "...                                                 ...     ...   \n",
      "1701  How many actions does it take to process the b...       1   \n",
      "1702  How many actions does it take to process the m...       1   \n",
      "1703                  How many times is the knife used?       2   \n",
      "1704  How many actions does it take to process the c...       1   \n",
      "1705                    How many times is the lid used?       1   \n",
      "\n",
      "                                                context  \n",
      "0     cut # result : chopped vegetables, tool : knif...  \n",
      "1     cut # result : chopped vegetables, tool : knif...  \n",
      "2     preheat the oven # part : preheat # to 350deg ...  \n",
      "3     preheat the oven # part : preheat # to 350deg ...  \n",
      "4     cook pasta # part : cook # in large salted # p...  \n",
      "...                                                 ...  \n",
      "1701  finely dice # tool : knife, habitat : cutting ...  \n",
      "1702  finely dice # tool : knife, habitat : cutting ...  \n",
      "1703  finely dice # tool : knife, habitat : cutting ...  \n",
      "1704  for cocoa mix , in a storage # part : combine ...  \n",
      "1705  for cocoa mix , in a storage # part : combine ...  \n",
      "\n",
      "[1706 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9040b3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp38-cp38-macosx_10_6_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 8.5 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.96\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7db3ddbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ALBERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bigbird-roberta-large were not used when initializing BigBirdForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BigBirdForSequenceClassification were not initialized from the model checkpoint at google/bigbird-roberta-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading ALBERT tokenizer...')\n",
    "l='allenai/longformer-large-4096-finetuned-triviaqa'\n",
    "b='google/bigbird-roberta-large'\n",
    "tokenizer = AutoTokenizer.from_pretrained(b, do_lower_case=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(b, num_labels=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "34cf3e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(**inputs, labels=labels)\n",
    "loss = outputs.loss\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a69527a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fbeccfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (50358, 1024)\n",
      "bert.embeddings.position_embeddings.weight              (4096, 1024)\n",
      "bert.embeddings.token_type_embeddings.weight               (2, 1024)\n",
      "bert.embeddings.LayerNorm.weight                             (1024,)\n",
      "bert.embeddings.LayerNorm.bias                               (1024,)\n",
      "bert.encoder.layer.0.attention.self.query.weight        (1024, 1024)\n",
      "bert.encoder.layer.0.attention.self.query.bias               (1024,)\n",
      "bert.encoder.layer.0.attention.self.key.weight          (1024, 1024)\n",
      "bert.encoder.layer.0.attention.self.key.bias                 (1024,)\n",
      "bert.encoder.layer.0.attention.self.value.weight        (1024, 1024)\n",
      "bert.encoder.layer.0.attention.self.value.bias               (1024,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight      (1024, 1024)\n",
      "bert.encoder.layer.0.attention.output.dense.bias             (1024,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight       (1024,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias         (1024,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight          (4096, 1024)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (4096,)\n",
      "bert.encoder.layer.0.output.dense.weight                (1024, 4096)\n",
      "bert.encoder.layer.0.output.dense.bias                       (1024,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                 (1024,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                   (1024,)\n",
      "bert.encoder.layer.1.attention.self.query.weight        (1024, 1024)\n",
      "bert.encoder.layer.1.attention.self.query.bias               (1024,)\n",
      "bert.encoder.layer.1.attention.self.key.weight          (1024, 1024)\n",
      "bert.encoder.layer.1.attention.self.key.bias                 (1024,)\n",
      "bert.encoder.layer.1.attention.self.value.weight        (1024, 1024)\n",
      "bert.encoder.layer.1.attention.self.value.bias               (1024,)\n",
      "bert.encoder.layer.1.attention.output.dense.weight      (1024, 1024)\n",
      "bert.encoder.layer.1.attention.output.dense.bias             (1024,)\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight       (1024,)\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias         (1024,)\n",
      "bert.encoder.layer.1.intermediate.dense.weight          (4096, 1024)\n",
      "bert.encoder.layer.1.intermediate.dense.bias                 (4096,)\n",
      "bert.encoder.layer.1.output.dense.weight                (1024, 4096)\n",
      "bert.encoder.layer.1.output.dense.bias                       (1024,)\n",
      "bert.encoder.layer.1.output.LayerNorm.weight                 (1024,)\n",
      "bert.encoder.layer.1.output.LayerNorm.bias                   (1024,)\n",
      "bert.encoder.layer.2.attention.self.query.weight        (1024, 1024)\n",
      "bert.encoder.layer.2.attention.self.query.bias               (1024,)\n",
      "bert.encoder.layer.2.attention.self.key.weight          (1024, 1024)\n",
      "bert.encoder.layer.2.attention.self.key.bias                 (1024,)\n",
      "bert.encoder.layer.2.attention.self.value.weight        (1024, 1024)\n",
      "bert.encoder.layer.2.attention.self.value.bias               (1024,)\n",
      "bert.encoder.layer.2.attention.output.dense.weight      (1024, 1024)\n",
      "bert.encoder.layer.2.attention.output.dense.bias             (1024,)\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight       (1024,)\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias         (1024,)\n",
      "bert.encoder.layer.2.intermediate.dense.weight          (4096, 1024)\n",
      "bert.encoder.layer.2.intermediate.dense.bias                 (4096,)\n",
      "bert.encoder.layer.2.output.dense.weight                (1024, 4096)\n",
      "bert.encoder.layer.2.output.dense.bias                       (1024,)\n",
      "bert.encoder.layer.2.output.LayerNorm.weight                 (1024,)\n",
      "bert.encoder.layer.2.output.LayerNorm.bias                   (1024,)\n",
      "bert.encoder.layer.3.attention.self.query.weight        (1024, 1024)\n",
      "bert.encoder.layer.3.attention.self.query.bias               (1024,)\n",
      "bert.encoder.layer.3.attention.self.key.weight          (1024, 1024)\n",
      "bert.encoder.layer.3.attention.self.key.bias                 (1024,)\n",
      "bert.encoder.layer.3.attention.self.value.weight        (1024, 1024)\n",
      "bert.encoder.layer.3.attention.self.value.bias               (1024,)\n",
      "bert.encoder.layer.3.attention.output.dense.weight      (1024, 1024)\n",
      "bert.encoder.layer.3.attention.output.dense.bias             (1024,)\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight       (1024,)\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias         (1024,)\n",
      "bert.encoder.layer.3.intermediate.dense.weight          (4096, 1024)\n",
      "bert.encoder.layer.3.intermediate.dense.bias                 (4096,)\n",
      "bert.encoder.layer.3.output.dense.weight                (1024, 4096)\n",
      "bert.encoder.layer.3.output.dense.bias                       (1024,)\n",
      "bert.encoder.layer.3.output.LayerNorm.weight                 (1024,)\n",
      "bert.encoder.layer.3.output.LayerNorm.bias                   (1024,)\n",
      "bert.encoder.layer.4.attention.self.query.weight        (1024, 1024)\n",
      "bert.encoder.layer.4.attention.self.query.bias               (1024,)\n",
      "bert.encoder.layer.4.attention.self.key.weight          (1024, 1024)\n",
      "bert.encoder.layer.4.attention.self.key.bias                 (1024,)\n",
      "bert.encoder.layer.4.attention.self.value.weight        (1024, 1024)\n",
      "bert.encoder.layer.4.attention.self.value.bias               (1024,)\n",
      "bert.encoder.layer.4.attention.output.dense.weight      (1024, 1024)\n",
      "bert.encoder.layer.4.attention.output.dense.bias             (1024,)\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight       (1024,)\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias         (1024,)\n",
      "bert.encoder.layer.4.intermediate.dense.weight          (4096, 1024)\n",
      "bert.encoder.layer.4.intermediate.dense.bias                 (4096,)\n",
      "bert.encoder.layer.4.output.dense.weight                (1024, 4096)\n",
      "bert.encoder.layer.4.output.dense.bias                       (1024,)\n",
      "bert.encoder.layer.4.output.LayerNorm.weight                 (1024,)\n",
      "bert.encoder.layer.4.output.LayerNorm.bias                   (1024,)\n",
      "bert.encoder.layer.5.attention.self.query.weight        (1024, 1024)\n",
      "bert.encoder.layer.5.attention.self.query.bias               (1024,)\n",
      "bert.encoder.layer.5.attention.self.key.weight          (1024, 1024)\n",
      "bert.encoder.layer.5.attention.self.key.bias                 (1024,)\n",
      "bert.encoder.layer.5.attention.self.value.weight        (1024, 1024)\n",
      "bert.encoder.layer.5.attention.self.value.bias               (1024,)\n",
      "bert.encoder.layer.5.attention.output.dense.weight      (1024, 1024)\n",
      "bert.encoder.layer.5.attention.output.dense.bias             (1024,)\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight       (1024,)\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias         (1024,)\n",
      "bert.encoder.layer.5.intermediate.dense.weight          (4096, 1024)\n",
      "bert.encoder.layer.5.intermediate.dense.bias                 (4096,)\n",
      "bert.encoder.layer.5.output.dense.weight                (1024, 4096)\n",
      "bert.encoder.layer.5.output.dense.bias                       (1024,)\n",
      "bert.encoder.layer.5.output.LayerNorm.weight                 (1024,)\n",
      "bert.encoder.layer.5.output.LayerNorm.bias                   (1024,)\n",
      "bert.encoder.layer.6.attention.self.query.weight        (1024, 1024)\n",
      "bert.encoder.layer.6.attention.self.query.bias               (1024,)\n",
      "bert.encoder.layer.6.attention.self.key.weight          (1024, 1024)\n",
      "bert.encoder.layer.6.attention.self.key.bias                 (1024,)\n",
      "bert.encoder.layer.6.attention.self.value.weight        (1024, 1024)\n",
      "bert.encoder.layer.6.attention.self.value.bias               (1024,)\n",
      "bert.encoder.layer.6.attention.output.dense.weight      (1024, 1024)\n",
      "bert.encoder.layer.6.attention.output.dense.bias             (1024,)\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight       (1024,)\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias         (1024,)\n",
      "bert.encoder.layer.6.intermediate.dense.weight          (4096, 1024)\n",
      "bert.encoder.layer.6.intermediate.dense.bias                 (4096,)\n",
      "bert.encoder.layer.6.output.dense.weight                (1024, 4096)\n",
      "bert.encoder.layer.6.output.dense.bias                       (1024,)\n",
      "bert.encoder.layer.6.output.LayerNorm.weight                 (1024,)\n",
      "bert.encoder.layer.6.output.LayerNorm.bias                   (1024,)\n",
      "bert.encoder.layer.7.attention.self.query.weight        (1024, 1024)\n",
      "bert.encoder.layer.7.attention.self.query.bias               (1024,)\n",
      "bert.encoder.layer.7.attention.self.key.weight          (1024, 1024)\n",
      "bert.encoder.layer.7.attention.self.key.bias                 (1024,)\n",
      "bert.encoder.layer.7.attention.self.value.weight        (1024, 1024)\n",
      "bert.encoder.layer.7.attention.self.value.bias               (1024,)\n",
      "bert.encoder.layer.7.attention.output.dense.weight      (1024, 1024)\n",
      "bert.encoder.layer.7.attention.output.dense.bias             (1024,)\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight       (1024,)\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias         (1024,)\n",
      "bert.encoder.layer.7.intermediate.dense.weight          (4096, 1024)\n",
      "bert.encoder.layer.7.intermediate.dense.bias                 (4096,)\n",
      "bert.encoder.layer.7.output.dense.weight                (1024, 4096)\n",
      "bert.encoder.layer.7.output.dense.bias                       (1024,)\n",
      "bert.encoder.layer.7.output.LayerNorm.weight                 (1024,)\n",
      "bert.encoder.layer.7.output.LayerNorm.bias                   (1024,)\n",
      "bert.encoder.layer.8.attention.self.query.weight        (1024, 1024)\n",
      "bert.encoder.layer.8.attention.self.query.bias               (1024,)\n",
      "bert.encoder.layer.8.attention.self.key.weight          (1024, 1024)\n",
      "bert.encoder.layer.8.attention.self.key.bias                 (1024,)\n",
      "bert.encoder.layer.8.attention.self.value.weight        (1024, 1024)\n",
      "bert.encoder.layer.8.attention.self.value.bias               (1024,)\n",
      "bert.encoder.layer.8.attention.output.dense.weight      (1024, 1024)\n",
      "bert.encoder.layer.8.attention.output.dense.bias             (1024,)\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight       (1024,)\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias         (1024,)\n",
      "bert.encoder.layer.8.intermediate.dense.weight          (4096, 1024)\n",
      "bert.encoder.layer.8.intermediate.dense.bias                 (4096,)\n",
      "bert.encoder.layer.8.output.dense.weight                (1024, 4096)\n",
      "bert.encoder.layer.8.output.dense.bias                       (1024,)\n",
      "bert.encoder.layer.8.output.LayerNorm.weight                 (1024,)\n",
      "bert.encoder.layer.8.output.LayerNorm.bias                   (1024,)\n",
      "bert.encoder.layer.9.attention.self.query.weight        (1024, 1024)\n",
      "bert.encoder.layer.9.attention.self.query.bias               (1024,)\n",
      "bert.encoder.layer.9.attention.self.key.weight          (1024, 1024)\n",
      "bert.encoder.layer.9.attention.self.key.bias                 (1024,)\n",
      "bert.encoder.layer.9.attention.self.value.weight        (1024, 1024)\n",
      "bert.encoder.layer.9.attention.self.value.bias               (1024,)\n",
      "bert.encoder.layer.9.attention.output.dense.weight      (1024, 1024)\n",
      "bert.encoder.layer.9.attention.output.dense.bias             (1024,)\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight       (1024,)\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias         (1024,)\n",
      "bert.encoder.layer.9.intermediate.dense.weight          (4096, 1024)\n",
      "bert.encoder.layer.9.intermediate.dense.bias                 (4096,)\n",
      "bert.encoder.layer.9.output.dense.weight                (1024, 4096)\n",
      "bert.encoder.layer.9.output.dense.bias                       (1024,)\n",
      "bert.encoder.layer.9.output.LayerNorm.weight                 (1024,)\n",
      "bert.encoder.layer.9.output.LayerNorm.bias                   (1024,)\n",
      "bert.encoder.layer.10.attention.self.query.weight       (1024, 1024)\n",
      "bert.encoder.layer.10.attention.self.query.bias              (1024,)\n",
      "bert.encoder.layer.10.attention.self.key.weight         (1024, 1024)\n",
      "bert.encoder.layer.10.attention.self.key.bias                (1024,)\n",
      "bert.encoder.layer.10.attention.self.value.weight       (1024, 1024)\n",
      "bert.encoder.layer.10.attention.self.value.bias              (1024,)\n",
      "bert.encoder.layer.10.attention.output.dense.weight     (1024, 1024)\n",
      "bert.encoder.layer.10.attention.output.dense.bias            (1024,)\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight      (1024,)\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias        (1024,)\n",
      "bert.encoder.layer.10.intermediate.dense.weight         (4096, 1024)\n",
      "bert.encoder.layer.10.intermediate.dense.bias                (4096,)\n",
      "bert.encoder.layer.10.output.dense.weight               (1024, 4096)\n",
      "bert.encoder.layer.10.output.dense.bias                      (1024,)\n",
      "bert.encoder.layer.10.output.LayerNorm.weight                (1024,)\n",
      "bert.encoder.layer.10.output.LayerNorm.bias                  (1024,)\n",
      "bert.encoder.layer.11.attention.self.query.weight       (1024, 1024)\n",
      "bert.encoder.layer.11.attention.self.query.bias              (1024,)\n",
      "bert.encoder.layer.11.attention.self.key.weight         (1024, 1024)\n",
      "bert.encoder.layer.11.attention.self.key.bias                (1024,)\n",
      "bert.encoder.layer.11.attention.self.value.weight       (1024, 1024)\n",
      "bert.encoder.layer.11.attention.self.value.bias              (1024,)\n",
      "bert.encoder.layer.11.attention.output.dense.weight     (1024, 1024)\n",
      "bert.encoder.layer.11.attention.output.dense.bias            (1024,)\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight      (1024,)\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias        (1024,)\n",
      "bert.encoder.layer.11.intermediate.dense.weight         (4096, 1024)\n",
      "bert.encoder.layer.11.intermediate.dense.bias                (4096,)\n",
      "bert.encoder.layer.11.output.dense.weight               (1024, 4096)\n",
      "bert.encoder.layer.11.output.dense.bias                      (1024,)\n",
      "bert.encoder.layer.11.output.LayerNorm.weight                (1024,)\n",
      "bert.encoder.layer.11.output.LayerNorm.bias                  (1024,)\n",
      "bert.encoder.layer.12.attention.self.query.weight       (1024, 1024)\n",
      "bert.encoder.layer.12.attention.self.query.bias              (1024,)\n",
      "bert.encoder.layer.12.attention.self.key.weight         (1024, 1024)\n",
      "bert.encoder.layer.12.attention.self.key.bias                (1024,)\n",
      "bert.encoder.layer.12.attention.self.value.weight       (1024, 1024)\n",
      "bert.encoder.layer.12.attention.self.value.bias              (1024,)\n",
      "bert.encoder.layer.12.attention.output.dense.weight     (1024, 1024)\n",
      "bert.encoder.layer.12.attention.output.dense.bias            (1024,)\n",
      "bert.encoder.layer.12.attention.output.LayerNorm.weight      (1024,)\n",
      "bert.encoder.layer.12.attention.output.LayerNorm.bias        (1024,)\n",
      "bert.encoder.layer.12.intermediate.dense.weight         (4096, 1024)\n",
      "bert.encoder.layer.12.intermediate.dense.bias                (4096,)\n",
      "bert.encoder.layer.12.output.dense.weight               (1024, 4096)\n",
      "bert.encoder.layer.12.output.dense.bias                      (1024,)\n",
      "bert.encoder.layer.12.output.LayerNorm.weight                (1024,)\n",
      "bert.encoder.layer.12.output.LayerNorm.bias                  (1024,)\n",
      "bert.encoder.layer.13.attention.self.query.weight       (1024, 1024)\n",
      "bert.encoder.layer.13.attention.self.query.bias              (1024,)\n",
      "bert.encoder.layer.13.attention.self.key.weight         (1024, 1024)\n",
      "bert.encoder.layer.13.attention.self.key.bias                (1024,)\n",
      "bert.encoder.layer.13.attention.self.value.weight       (1024, 1024)\n",
      "bert.encoder.layer.13.attention.self.value.bias              (1024,)\n",
      "bert.encoder.layer.13.attention.output.dense.weight     (1024, 1024)\n",
      "bert.encoder.layer.13.attention.output.dense.bias            (1024,)\n",
      "bert.encoder.layer.13.attention.output.LayerNorm.weight      (1024,)\n",
      "bert.encoder.layer.13.attention.output.LayerNorm.bias        (1024,)\n",
      "bert.encoder.layer.13.intermediate.dense.weight         (4096, 1024)\n",
      "bert.encoder.layer.13.intermediate.dense.bias                (4096,)\n",
      "bert.encoder.layer.13.output.dense.weight               (1024, 4096)\n",
      "bert.encoder.layer.13.output.dense.bias                      (1024,)\n",
      "bert.encoder.layer.13.output.LayerNorm.weight                (1024,)\n",
      "bert.encoder.layer.13.output.LayerNorm.bias                  (1024,)\n",
      "bert.encoder.layer.14.attention.self.query.weight       (1024, 1024)\n",
      "bert.encoder.layer.14.attention.self.query.bias              (1024,)\n",
      "bert.encoder.layer.14.attention.self.key.weight         (1024, 1024)\n",
      "bert.encoder.layer.14.attention.self.key.bias                (1024,)\n",
      "bert.encoder.layer.14.attention.self.value.weight       (1024, 1024)\n",
      "bert.encoder.layer.14.attention.self.value.bias              (1024,)\n",
      "bert.encoder.layer.14.attention.output.dense.weight     (1024, 1024)\n",
      "bert.encoder.layer.14.attention.output.dense.bias            (1024,)\n",
      "bert.encoder.layer.14.attention.output.LayerNorm.weight      (1024,)\n",
      "bert.encoder.layer.14.attention.output.LayerNorm.bias        (1024,)\n",
      "bert.encoder.layer.14.intermediate.dense.weight         (4096, 1024)\n",
      "bert.encoder.layer.14.intermediate.dense.bias                (4096,)\n",
      "bert.encoder.layer.14.output.dense.weight               (1024, 4096)\n",
      "bert.encoder.layer.14.output.dense.bias                      (1024,)\n",
      "bert.encoder.layer.14.output.LayerNorm.weight                (1024,)\n",
      "bert.encoder.layer.14.output.LayerNorm.bias                  (1024,)\n",
      "bert.encoder.layer.15.attention.self.query.weight       (1024, 1024)\n",
      "bert.encoder.layer.15.attention.self.query.bias              (1024,)\n",
      "bert.encoder.layer.15.attention.self.key.weight         (1024, 1024)\n",
      "bert.encoder.layer.15.attention.self.key.bias                (1024,)\n",
      "bert.encoder.layer.15.attention.self.value.weight       (1024, 1024)\n",
      "bert.encoder.layer.15.attention.self.value.bias              (1024,)\n",
      "bert.encoder.layer.15.attention.output.dense.weight     (1024, 1024)\n",
      "bert.encoder.layer.15.attention.output.dense.bias            (1024,)\n",
      "bert.encoder.layer.15.attention.output.LayerNorm.weight      (1024,)\n",
      "bert.encoder.layer.15.attention.output.LayerNorm.bias        (1024,)\n",
      "bert.encoder.layer.15.intermediate.dense.weight         (4096, 1024)\n",
      "bert.encoder.layer.15.intermediate.dense.bias                (4096,)\n",
      "bert.encoder.layer.15.output.dense.weight               (1024, 4096)\n",
      "bert.encoder.layer.15.output.dense.bias                      (1024,)\n",
      "bert.encoder.layer.15.output.LayerNorm.weight                (1024,)\n",
      "bert.encoder.layer.15.output.LayerNorm.bias                  (1024,)\n",
      "bert.encoder.layer.16.attention.self.query.weight       (1024, 1024)\n",
      "bert.encoder.layer.16.attention.self.query.bias              (1024,)\n",
      "bert.encoder.layer.16.attention.self.key.weight         (1024, 1024)\n",
      "bert.encoder.layer.16.attention.self.key.bias                (1024,)\n",
      "bert.encoder.layer.16.attention.self.value.weight       (1024, 1024)\n",
      "bert.encoder.layer.16.attention.self.value.bias              (1024,)\n",
      "bert.encoder.layer.16.attention.output.dense.weight     (1024, 1024)\n",
      "bert.encoder.layer.16.attention.output.dense.bias            (1024,)\n",
      "bert.encoder.layer.16.attention.output.LayerNorm.weight      (1024,)\n",
      "bert.encoder.layer.16.attention.output.LayerNorm.bias        (1024,)\n",
      "bert.encoder.layer.16.intermediate.dense.weight         (4096, 1024)\n",
      "bert.encoder.layer.16.intermediate.dense.bias                (4096,)\n",
      "bert.encoder.layer.16.output.dense.weight               (1024, 4096)\n",
      "bert.encoder.layer.16.output.dense.bias                      (1024,)\n",
      "bert.encoder.layer.16.output.LayerNorm.weight                (1024,)\n",
      "bert.encoder.layer.16.output.LayerNorm.bias                  (1024,)\n",
      "bert.encoder.layer.17.attention.self.query.weight       (1024, 1024)\n",
      "bert.encoder.layer.17.attention.self.query.bias              (1024,)\n",
      "bert.encoder.layer.17.attention.self.key.weight         (1024, 1024)\n",
      "bert.encoder.layer.17.attention.self.key.bias                (1024,)\n",
      "bert.encoder.layer.17.attention.self.value.weight       (1024, 1024)\n",
      "bert.encoder.layer.17.attention.self.value.bias              (1024,)\n",
      "bert.encoder.layer.17.attention.output.dense.weight     (1024, 1024)\n",
      "bert.encoder.layer.17.attention.output.dense.bias            (1024,)\n",
      "bert.encoder.layer.17.attention.output.LayerNorm.weight      (1024,)\n",
      "bert.encoder.layer.17.attention.output.LayerNorm.bias        (1024,)\n",
      "bert.encoder.layer.17.intermediate.dense.weight         (4096, 1024)\n",
      "bert.encoder.layer.17.intermediate.dense.bias                (4096,)\n",
      "bert.encoder.layer.17.output.dense.weight               (1024, 4096)\n",
      "bert.encoder.layer.17.output.dense.bias                      (1024,)\n",
      "bert.encoder.layer.17.output.LayerNorm.weight                (1024,)\n",
      "bert.encoder.layer.17.output.LayerNorm.bias                  (1024,)\n",
      "bert.encoder.layer.18.attention.self.query.weight       (1024, 1024)\n",
      "bert.encoder.layer.18.attention.self.query.bias              (1024,)\n",
      "bert.encoder.layer.18.attention.self.key.weight         (1024, 1024)\n",
      "bert.encoder.layer.18.attention.self.key.bias                (1024,)\n",
      "bert.encoder.layer.18.attention.self.value.weight       (1024, 1024)\n",
      "bert.encoder.layer.18.attention.self.value.bias              (1024,)\n",
      "bert.encoder.layer.18.attention.output.dense.weight     (1024, 1024)\n",
      "bert.encoder.layer.18.attention.output.dense.bias            (1024,)\n",
      "bert.encoder.layer.18.attention.output.LayerNorm.weight      (1024,)\n",
      "bert.encoder.layer.18.attention.output.LayerNorm.bias        (1024,)\n",
      "bert.encoder.layer.18.intermediate.dense.weight         (4096, 1024)\n",
      "bert.encoder.layer.18.intermediate.dense.bias                (4096,)\n",
      "bert.encoder.layer.18.output.dense.weight               (1024, 4096)\n",
      "bert.encoder.layer.18.output.dense.bias                      (1024,)\n",
      "bert.encoder.layer.18.output.LayerNorm.weight                (1024,)\n",
      "bert.encoder.layer.18.output.LayerNorm.bias                  (1024,)\n",
      "bert.encoder.layer.19.attention.self.query.weight       (1024, 1024)\n",
      "bert.encoder.layer.19.attention.self.query.bias              (1024,)\n",
      "bert.encoder.layer.19.attention.self.key.weight         (1024, 1024)\n",
      "bert.encoder.layer.19.attention.self.key.bias                (1024,)\n",
      "bert.encoder.layer.19.attention.self.value.weight       (1024, 1024)\n",
      "bert.encoder.layer.19.attention.self.value.bias              (1024,)\n",
      "bert.encoder.layer.19.attention.output.dense.weight     (1024, 1024)\n",
      "bert.encoder.layer.19.attention.output.dense.bias            (1024,)\n",
      "bert.encoder.layer.19.attention.output.LayerNorm.weight      (1024,)\n",
      "bert.encoder.layer.19.attention.output.LayerNorm.bias        (1024,)\n",
      "bert.encoder.layer.19.intermediate.dense.weight         (4096, 1024)\n",
      "bert.encoder.layer.19.intermediate.dense.bias                (4096,)\n",
      "bert.encoder.layer.19.output.dense.weight               (1024, 4096)\n",
      "bert.encoder.layer.19.output.dense.bias                      (1024,)\n",
      "bert.encoder.layer.19.output.LayerNorm.weight                (1024,)\n",
      "bert.encoder.layer.19.output.LayerNorm.bias                  (1024,)\n",
      "bert.encoder.layer.20.attention.self.query.weight       (1024, 1024)\n",
      "bert.encoder.layer.20.attention.self.query.bias              (1024,)\n",
      "bert.encoder.layer.20.attention.self.key.weight         (1024, 1024)\n",
      "bert.encoder.layer.20.attention.self.key.bias                (1024,)\n",
      "bert.encoder.layer.20.attention.self.value.weight       (1024, 1024)\n",
      "bert.encoder.layer.20.attention.self.value.bias              (1024,)\n",
      "bert.encoder.layer.20.attention.output.dense.weight     (1024, 1024)\n",
      "bert.encoder.layer.20.attention.output.dense.bias            (1024,)\n",
      "bert.encoder.layer.20.attention.output.LayerNorm.weight      (1024,)\n",
      "bert.encoder.layer.20.attention.output.LayerNorm.bias        (1024,)\n",
      "bert.encoder.layer.20.intermediate.dense.weight         (4096, 1024)\n",
      "bert.encoder.layer.20.intermediate.dense.bias                (4096,)\n",
      "bert.encoder.layer.20.output.dense.weight               (1024, 4096)\n",
      "bert.encoder.layer.20.output.dense.bias                      (1024,)\n",
      "bert.encoder.layer.20.output.LayerNorm.weight                (1024,)\n",
      "bert.encoder.layer.20.output.LayerNorm.bias                  (1024,)\n",
      "bert.encoder.layer.21.attention.self.query.weight       (1024, 1024)\n",
      "bert.encoder.layer.21.attention.self.query.bias              (1024,)\n",
      "bert.encoder.layer.21.attention.self.key.weight         (1024, 1024)\n",
      "bert.encoder.layer.21.attention.self.key.bias                (1024,)\n",
      "bert.encoder.layer.21.attention.self.value.weight       (1024, 1024)\n",
      "bert.encoder.layer.21.attention.self.value.bias              (1024,)\n",
      "bert.encoder.layer.21.attention.output.dense.weight     (1024, 1024)\n",
      "bert.encoder.layer.21.attention.output.dense.bias            (1024,)\n",
      "bert.encoder.layer.21.attention.output.LayerNorm.weight      (1024,)\n",
      "bert.encoder.layer.21.attention.output.LayerNorm.bias        (1024,)\n",
      "bert.encoder.layer.21.intermediate.dense.weight         (4096, 1024)\n",
      "bert.encoder.layer.21.intermediate.dense.bias                (4096,)\n",
      "bert.encoder.layer.21.output.dense.weight               (1024, 4096)\n",
      "bert.encoder.layer.21.output.dense.bias                      (1024,)\n",
      "bert.encoder.layer.21.output.LayerNorm.weight                (1024,)\n",
      "bert.encoder.layer.21.output.LayerNorm.bias                  (1024,)\n",
      "bert.encoder.layer.22.attention.self.query.weight       (1024, 1024)\n",
      "bert.encoder.layer.22.attention.self.query.bias              (1024,)\n",
      "bert.encoder.layer.22.attention.self.key.weight         (1024, 1024)\n",
      "bert.encoder.layer.22.attention.self.key.bias                (1024,)\n",
      "bert.encoder.layer.22.attention.self.value.weight       (1024, 1024)\n",
      "bert.encoder.layer.22.attention.self.value.bias              (1024,)\n",
      "bert.encoder.layer.22.attention.output.dense.weight     (1024, 1024)\n",
      "bert.encoder.layer.22.attention.output.dense.bias            (1024,)\n",
      "bert.encoder.layer.22.attention.output.LayerNorm.weight      (1024,)\n",
      "bert.encoder.layer.22.attention.output.LayerNorm.bias        (1024,)\n",
      "bert.encoder.layer.22.intermediate.dense.weight         (4096, 1024)\n",
      "bert.encoder.layer.22.intermediate.dense.bias                (4096,)\n",
      "bert.encoder.layer.22.output.dense.weight               (1024, 4096)\n",
      "bert.encoder.layer.22.output.dense.bias                      (1024,)\n",
      "bert.encoder.layer.22.output.LayerNorm.weight                (1024,)\n",
      "bert.encoder.layer.22.output.LayerNorm.bias                  (1024,)\n",
      "bert.encoder.layer.23.attention.self.query.weight       (1024, 1024)\n",
      "bert.encoder.layer.23.attention.self.query.bias              (1024,)\n",
      "bert.encoder.layer.23.attention.self.key.weight         (1024, 1024)\n",
      "bert.encoder.layer.23.attention.self.key.bias                (1024,)\n",
      "bert.encoder.layer.23.attention.self.value.weight       (1024, 1024)\n",
      "bert.encoder.layer.23.attention.self.value.bias              (1024,)\n",
      "bert.encoder.layer.23.attention.output.dense.weight     (1024, 1024)\n",
      "bert.encoder.layer.23.attention.output.dense.bias            (1024,)\n",
      "bert.encoder.layer.23.attention.output.LayerNorm.weight      (1024,)\n",
      "bert.encoder.layer.23.attention.output.LayerNorm.bias        (1024,)\n",
      "bert.encoder.layer.23.intermediate.dense.weight         (4096, 1024)\n",
      "bert.encoder.layer.23.intermediate.dense.bias                (4096,)\n",
      "bert.encoder.layer.23.output.dense.weight               (1024, 4096)\n",
      "bert.encoder.layer.23.output.dense.bias                      (1024,)\n",
      "bert.encoder.layer.23.output.LayerNorm.weight                (1024,)\n",
      "bert.encoder.layer.23.output.LayerNorm.bias                  (1024,)\n",
      "bert.pooler.weight                                      (1024, 1024)\n",
      "bert.pooler.bias                                             (1024,)\n",
      "classifier.dense.weight                                 (1024, 1024)\n",
      "classifier.dense.bias                                        (1024,)\n",
      "classifier.out_proj.weight                                 (3, 1024)\n",
      "classifier.out_proj.bias                                        (3,)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fcec816d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  895\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./qa_0.csv')\n",
    "\n",
    "max_len = 0\n",
    "\n",
    "# For every sentence...\n",
    "for sent in df.context.values:\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53c211fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/rickzhai/opt/anaconda3/lib/python3.8/site-packages (1.10.0)\n",
      "Requirement already satisfied: typing_extensions in /Users/rickzhai/opt/anaconda3/lib/python3.8/site-packages (from torch) (3.7.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8050f7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/rickzhai/opt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "sentences = df.context.values\n",
    "qs = df.question.values\n",
    "# For every sentence...\n",
    "for sent in zip(qs,sentences):\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent[0],\n",
    "                        sent[1],                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                                  # Pad & truncate all sentences.\n",
    "                                   # Pad & truncate all sentences.\n",
    "                        max_length = 1024,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "#labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "#print('Original: ', sentences[0])\n",
    "#print(input_ids[0][:273])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7695204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   65,  1475,   968,  4129,   958,   441,  1112,   385,  1530,   363,\n",
      "        48528,  6275,   131,    66,  2106,  1404,  1356,  1159, 20821, 13802,\n",
      "          112,  2992,  1159,  9946,  1404,   363, 44754,  1404,   737,  1159,\n",
      "         2106,  1404,   757,   882, 47198,  8105,   391,   363, 10818,  1404,\n",
      "          737,  1159,  2106,  1404,   757, 13298,   633,  2647,  5308,  2263,\n",
      "         2106,  1404,  2992,  1159,  9946,  1404, 34498,  1404,   737,  1159,\n",
      "         2106,  1404,   391,  2077,  1330, 45146,  1404,   737,  1159,  2106,\n",
      "         1404,   757, 34997,   865,   574,  1234,  1404, 20119,  1159,  3526,\n",
      "         1404, 21771,  1404,   737,  1159,   574,  1234,  1404,   388,   463,\n",
      "        30165,   387, 19551,  1404,   737,  1159,   574,  1234,  1404,  3157,\n",
      "          938,   852,  1404,  1356,  1159, 15948, 13802,   112, 20119,  1159,\n",
      "         3526,  1404, 20821,  1404,   737,  1159,   852,  1404, 13802,   391,\n",
      "         4356,   430,   939,  2532,   726,  1978,  4995,   938, 26648, 10592,\n",
      "          865,   388,   358,  4654,  3526,  1404,   737,  1159,   574,  1234,\n",
      "         1404,   574,  1234, 48528,  1404,   737,  1159,   574,  1234,  1404,\n",
      "         6275,  7264,  1404,  2992,  1159, 15347,  4813,  1404,   441,   611,\n",
      "          981,   938,   391, 11341,  1404,  2992,  1159, 15347,  4813,  1404,\n",
      "          430,   819,   633,   908,  2532,  1667,   966, 12091,   865,   852,\n",
      "          363, 19884,  2918,  1404,   737,  1159,   852,  1404, 24073,   385,\n",
      "          363, 15948, 13802,   938, 30508,  1404,  2992,  1159, 24657,  1404,\n",
      "          707, 36177,   407,   938, 11341,  1404,  2992,  1159, 24657,  1404,\n",
      "          391, 12183,   865,  4452,  1404,  1356,  1159, 13802,   391, 48528,\n",
      "         6275,   370, 21713, 18191,  1404,   363,  6275,  1404,   737,  1159,\n",
      "         4452,  1404,   757,   363,  3526,   452,   363, 13802,   938,  1723,\n",
      "          452,  8369,  1404,   737,  1159,  1723,  1404,   391, 13486,  1404,\n",
      "          737,  1159,  1723,  1404,   938,  5123, 13871,   385, 12183,   578,\n",
      "         9492,  1404,   737,  1159, 12183,  1404,   865,  4792,  1404,  4369,\n",
      "         1159, 13802,   391, 48528,  6275,   370, 21713, 18191,  1404,   452,\n",
      "        15948,  1404,   737,  1159,  4792,  1404, 11565,   494,  1324,  2193,\n",
      "          458,   864, 16342,   617,   938, 49260, 18922,  1368,   865,   321,\n",
      "           66,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids[0][:310])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe205757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 1 0 0 1 0 0 1 2 0 0 0 0 0 0 1 0 1 0 0 2\n",
      " 0 0 0 0 0 0 1 1 2 0 1 2 1 1 1 1 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 2 0 2 1 1 1 1 0 0 0 1 0 1 0 0 1 2 0 2 1 0 2\n",
      " 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 2 2 0 0 1 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 2 0 0 0 0 0 1 0 2 0 0 0 0 0 1 0 1 0 0 0 0 1\n",
      " 1 0 0 1 1 1 0 0 0 0 1 0 1 0 2 0 0 0 1 0 0 0 0 0 1 0 2 0 0 1 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 1 2 1 0 0 0 0 2 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 1 1 1 0 1 0 1 0 1 1 0 0 0 0 2 0 1 0 0 1 1 2 0 1\n",
      " 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "labels = df.answer.astype(int).values -1\n",
    "print(labels[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bfe3c1",
   "metadata": {},
   "source": [
    "# extract text & tag columns.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2cf67e1",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile('[^a-zA-Z]') # to remove .1.2.3 in tags\n",
    "    \n",
    "with open(r\"/Users/rickzhai/Documents/GitHub/ITNLP_Semeval2022_Task6/crl_srl.csv\", 'r', encoding='utf-8') as f:\n",
    "    all_data = f.readlines()\n",
    "all_text_tag = []  # store all text tag columns\n",
    "i = 1\n",
    "while i < 219124:\n",
    "    doc_id = all_data[i - 1].split(\"=\")[1].strip(\"\\n\")  \n",
    "    text_tags = []  \n",
    "    while i < 219124 and 'newdoc id' not in all_data[i]:\n",
    "        item = all_data[i]\n",
    "        if i+1 < 219124:\n",
    "            item_next = all_data[i + 1] \n",
    "        \n",
    "        if 'text =' in item:\n",
    "            item_pre = all_data[i - 1]\n",
    "            if 'ingredients' in item_pre:\n",
    "                i += 1\n",
    "                pass\n",
    "            else:\n",
    "                i += 1\n",
    "                temp_text_tags = {}\n",
    "                texts, tagcols = \"\", {}\n",
    "\n",
    "                tagcols['word'] = []\n",
    "                tagcols['lemma'] = []\n",
    "                tagcols['pos'] = []\n",
    "                tagcols['entity'] = []\n",
    "                tagcols['part'] = []\n",
    "                tagcols['result'] = []\n",
    "                tagcols['hidden'] = []\n",
    "                tagcols['coref'] = []\n",
    "                tagcols['prdct'] = []\n",
    "                tagcols['arg1'] = []\n",
    "                tagcols['arg2'] = []\n",
    "                tagcols['arg3'] = []\n",
    "                tagcols['arg4'] = []\n",
    "                tagcols['arg5'] = []\n",
    "                tagcols['arg6'] = []\n",
    "                tagcols['arg7'] = []\n",
    "                tagcols['arg8'] = []\n",
    "                tagcols['arg9'] = []\n",
    "                tagcols['arg10'] = []\n",
    "                \n",
    "\n",
    "                while i < 219125 and all_data[i] and \"sent_id\" not in all_data[i] and 'newdoc id' not in all_data[i]: \n",
    "                    if \"newpar id\" in all_data[i]:\n",
    "                        i += 1\n",
    "                        continue\n",
    "                    item = all_data[i]\n",
    "\n",
    "                    tags = item.strip().split(\"\\t\")\n",
    "                    if len(tags) != 1:\n",
    "\n",
    "                        tagcols['word'].append(tags[1])\n",
    "                        tagcols['lemma'].append(tags[2])\n",
    "                        tagcols['pos'].append(tags[3])\n",
    "                        tagcols['entity'].append(tags[4])\n",
    "                        tagcols['part'].append(tags[5])\n",
    "                        tagcols['result'].append(tags[6])\n",
    "                        tagcols['hidden'].append(useful_tag_8(tags[7])) # list of hidden tags ['shadow : water', 'habitat : pot']\n",
    "                        tagcols['coref'].append(tags[8])\n",
    "                        tagcols['prdct'].append(tags[9])\n",
    "                        tagcols['arg1'].append(tags[10])\n",
    "                        tagcols['arg2'].append(tags[11])\n",
    "                        tagcols['arg3'].append(tags[12])\n",
    "                        tagcols['arg4'].append(tags[13])\n",
    "                        tagcols['arg5'].append(tags[14])\n",
    "                        tagcols['arg6'].append(tags[15])\n",
    "                        tagcols['arg7'].append(tags[16])\n",
    "                        tagcols['arg8'].append(tags[17])\n",
    "                        tagcols['arg9'].append(tags[18])\n",
    "                        tagcols['arg10'].append(tags[19])\n",
    "                        \n",
    "                        texts += (\" \" + tags[1].lower())\n",
    "\n",
    "                    i += 1\n",
    "                temp_text_tags[\"text\"] = texts.strip()\n",
    "                tagcols['part'] = part_to_text(tagcols['part'],temp_text_tags[\"text\"]) # from coref number to the word\n",
    "                temp_text_tags[\"tagcols\"] = tagcols\n",
    "                text_tags.append(temp_text_tags)\n",
    "        else:\n",
    "            i += 1\n",
    "    i += 1\n",
    "\n",
    "    doc_dict = {}\n",
    "    doc_dict['doc_id'] = doc_id\n",
    "    doc_dict['text_tags'] = text_tags\n",
    "    all_text_tag.append(doc_dict)\n",
    "fw = open(\"all_text_tag.json\", \"w\", encoding=\"utf-8\")\n",
    "json.dump(all_text_tag, fw, ensure_ascii=False, indent=4)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259c45b9",
   "metadata": {},
   "source": [
    "# preprocess tags \n",
    "## make them pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b0c8a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import re\n",
    "    regex = re.compile('[^a-zA-Z]') # to remove .1.2.3 and _ in hidden tags\n",
    "\n",
    "    def useful_tag_8(tags: str):\n",
    "        tags = tags.lower()\n",
    "        if \"|\" in tags:\n",
    "            tags = tags.split(\"|\")\n",
    "            ans = []\n",
    "            for tag in tags:\n",
    "                if tag:\n",
    "                    name, tag = tag.split(\"=\")\n",
    "                    taglist = tag.split(\":\")\n",
    "                    regextaglist = [regex.sub(' ', _) for _ in taglist]\n",
    "                    \n",
    "                    alltag = \" \".join(regextaglist)\n",
    "                    ans.append(name + \" : \" + alltag)\n",
    "                    # replace multiple blankspace with one\n",
    "                    newans = [' '.join(_.split()) for _ in ans] \n",
    "            if len(newans) != 0:\n",
    "                return newans\n",
    "            else:\n",
    "                return \"_\"\n",
    "        \n",
    "        else:\n",
    "            ans = []\n",
    "            if tags != '_':\n",
    "                \n",
    "                name, tag = tags.split(\"=\")\n",
    "                taglist = tag.split(\":\")\n",
    "                regextaglist = [regex.sub(' ', _) for _ in taglist]\n",
    "               \n",
    "                alltag = \" \".join(regextaglist)\n",
    "                ans.append(name + \" : \" + alltag)\n",
    "                newans = [' '.join(_.split()) for _ in ans]\n",
    "                if len(newans) != 0:\n",
    "                    return newans\n",
    "            else:\n",
    "                return \"_\"\n",
    "\n",
    "    def part_to_text(partlist:list,text:str): # change part number to the word\n",
    "        text_list = text.split()\n",
    "        for i, _ in enumerate(partlist):\n",
    "            if _ != '_':\n",
    "                partlist[i] = text_list[int(_)-1]\n",
    "        return partlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0928cf",
   "metadata": {},
   "source": [
    "# merge text and tag\n",
    "## in the form: ' text text # TAG = tag # # TAG = tag # text text '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b97ae550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def mergeTextTag(columns:tuple, jsonFile):\n",
    "    \n",
    "    '''\n",
    "    merge text and tags from json file in the form:    \n",
    "    text text # TAG = tag # # TAG = tag # text text .\n",
    "    \n",
    "    parameters: \n",
    "        columns: tuple of str, where the tags are from, tags can from multiple columns\n",
    "        json: str, the input json file address\n",
    "    \n",
    "    input: \n",
    "        column idx in tuple\n",
    "        json data file\n",
    "        \n",
    "    '''\n",
    "    file = json.load(jsonFile)\n",
    "    paddeddata = []\n",
    "    \n",
    "    for each_doc in file:\n",
    "        paddeddoc = {}\n",
    "        paddeddoc['text']=[]\n",
    "        paddeddoc['doc_id']=each_doc['doc_id'].strip()\n",
    "        \n",
    "        texttag_list = each_doc['text_tags'] # list\n",
    "        \n",
    "        # allign each word with target columns tags of it\n",
    "        for _ in texttag_list: \n",
    "            tags = _['tagcols'] \n",
    "            text_list = _['text'].split(' ') # the sentence list\n",
    "            \n",
    "            # combine cols of tags together in list.\n",
    "            tags_to_merge = [list(t) for t in zip(tags[c] for c in columns)] \n",
    "            unested = [list(itertools.chain(*sub)) for sub in tags_to_merge]\n",
    "            \n",
    "            # unzip the hidden tag list\n",
    "            for l in unested:\n",
    "                for i, v in enumerate(l):\n",
    "                    if type(v) == list:\n",
    "                        l[i] = ', '.join(v)\n",
    "            \n",
    "            # add '#' at the start and end of tags \n",
    "            newtag = []\n",
    "            for idx, _ in enumerate(zip(*unested)): # add tag name and '#' for not meaningful tags\n",
    "                if not all( l == '_' for l in _ ):\n",
    "                    hashpadlist =['# ' + columns[i] + ' : ' + t + ' # ' \\\n",
    "                                for i, t in enumerate(_) if t != '_']\n",
    "                    hashpad = ' '.join(hashpadlist)\n",
    "                    newtag.append(hashpad)\n",
    "                else:\n",
    "                    newtag.append('')\n",
    "            \n",
    "            paddedtext = ''\n",
    "            # and merge with the text list \n",
    "            \n",
    "            for text, tag in zip(text_list, newtag):\n",
    "                paddedtext += text + ' ' + tag\n",
    "            pt = paddedtext.replace('hidden : ','')\n",
    "            # append padded text to the list\n",
    "            paddeddoc['text'].append(pt)\n",
    "        paddeddata.append(paddeddoc)\n",
    "    return paddeddata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "94dea941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "jsonpath = r'/Users/rickzhai/Documents/GitHub/ITNLP_Semeval2022_Task6/number_reasoning/all_text_tag.json'\n",
    "f = open(jsonpath, 'r', encoding='utf-8')\n",
    "padded = mergeTextTag(columns=('part','hidden'), jsonFile=f)\n",
    "w = open(\"padded_text_0_1.json\", \"w\", encoding=\"utf-8\")\n",
    "json.dump(padded, w, ensure_ascii=False, indent=4)\n",
    "w.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e35a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
