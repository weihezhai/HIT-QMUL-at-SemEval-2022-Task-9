{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01dc5dc3",
   "metadata": {},
   "source": [
    "# extract type 0 data only\n",
    "## and removed answers with magnitude more than 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3424be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def extract_id(start_token='0', filepath=r'alldata.json'):\n",
    "    start = start_token\n",
    "    texts = []\n",
    "    with open(filepath,\"r\",encoding='utf-8') as f:\n",
    "        data=json.load(f)\n",
    "    for key,item in data.items():\n",
    "        questions=item['question']\n",
    "        for q in questions:\n",
    "            q_temp,a=q.split('     ')\n",
    "            idx,q = q_temp.split(\"=\")\n",
    "            idx_=idx.split(\" \")[-2]\n",
    "            if idx_.startswith(start) and int(a)<=3:\n",
    "                text={}\n",
    "                text['q_id']=idx_\n",
    "                text['question']=q.strip()\n",
    "                text['answer']=a\n",
    "                text['doc_id']=key.strip()\n",
    "                texts.append(text)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c816a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract type 0 qa pairs\n",
    "fp = '/Users/rickzhai/Documents/GitHub/ITNLP_Semeval2022_Task6/allqapairs.json'\n",
    "t = extract_id(start_token='0', filepath=fp)\n",
    "write = open(\"qa_0.json\", \"w\", encoding=\"utf-8\")\n",
    "json.dump(t, write, ensure_ascii=False, indent=4)\n",
    "write.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7afe50f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'n/a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-16b591a81119>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n/a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'n/a'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3598867",
   "metadata": {},
   "source": [
    "# create csv file as type_0 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3544f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9bfe3c1",
   "metadata": {},
   "source": [
    "# extract text & tag columns.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2cf67e1",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile('[^a-zA-Z]') # to remove .1.2.3 in tags\n",
    "    \n",
    "with open(r\"/Users/rickzhai/Documents/GitHub/ITNLP_Semeval2022_Task6/crl_srl.csv\", 'r', encoding='utf-8') as f:\n",
    "    all_data = f.readlines()\n",
    "all_text_tag = []  # store all text tag columns\n",
    "i = 1\n",
    "while i < 219124:\n",
    "    doc_id = all_data[i - 1].split(\"=\")[1].strip(\"\\n\")  \n",
    "    text_tags = []  \n",
    "    while i < 219124 and 'newdoc id' not in all_data[i]:\n",
    "        item = all_data[i]\n",
    "        if i+1 < 219124:\n",
    "            item_next = all_data[i + 1] \n",
    "        \n",
    "        if 'text =' in item:\n",
    "            item_pre = all_data[i - 1]\n",
    "            if 'ingredients' in item_pre:\n",
    "                i += 1\n",
    "                pass\n",
    "            else:\n",
    "                i += 1\n",
    "                temp_text_tags = {}\n",
    "                texts, tagcols = \"\", {}\n",
    "\n",
    "                tagcols['word'] = []\n",
    "                tagcols['lemma'] = []\n",
    "                tagcols['pos'] = []\n",
    "                tagcols['entity'] = []\n",
    "                tagcols['part'] = []\n",
    "                tagcols['result'] = []\n",
    "                tagcols['hidden'] = []\n",
    "                tagcols['coref'] = []\n",
    "                tagcols['prdct'] = []\n",
    "                tagcols['arg1'] = []\n",
    "                tagcols['arg2'] = []\n",
    "                tagcols['arg3'] = []\n",
    "                tagcols['arg4'] = []\n",
    "                tagcols['arg5'] = []\n",
    "\n",
    "                while i < 219125 and all_data[i] and \"sent_id\" not in all_data[i] and 'newdoc id' not in all_data[i]: \n",
    "                    if \"newpar id\" in all_data[i]:\n",
    "                        i += 1\n",
    "                        continue\n",
    "                    item = all_data[i]\n",
    "\n",
    "                    tags = item.strip().split(\"\\t\")\n",
    "                    if len(tags) != 1:\n",
    "\n",
    "                        tagcols['word'].append(tags[1])\n",
    "                        tagcols['lemma'].append(tags[2])\n",
    "                        tagcols['pos'].append(tags[3])\n",
    "                        tagcols['entity'].append(tags[4])\n",
    "                        tagcols['part'].append(tags[5])\n",
    "                        tagcols['result'].append(tags[6])\n",
    "                        tagcols['hidden'].append(useful_tag_8(tags[7])) # list of hidden tags ['shadow : water', 'habitat : pot']\n",
    "                        tagcols['coref'].append(tags[8])\n",
    "                        tagcols['prdct'].append(tags[9])\n",
    "                        tagcols['arg1'].append(tags[10])\n",
    "                        tagcols['arg2'].append(tags[11])\n",
    "                        tagcols['arg3'].append(tags[12])\n",
    "                        tagcols['arg4'].append(tags[13])\n",
    "                        tagcols['arg5'].append(tags[14])\n",
    "                        texts += (\" \" + tags[1].lower())\n",
    "\n",
    "                    i += 1\n",
    "                temp_text_tags[\"text\"] = texts.strip()\n",
    "                tagcols['part'] = part_to_text(tagcols['part'],temp_text_tags[\"text\"]) # from coref number to the word\n",
    "                temp_text_tags[\"tagcols\"] = tagcols\n",
    "                text_tags.append(temp_text_tags)\n",
    "        else:\n",
    "            i += 1\n",
    "    i += 1\n",
    "\n",
    "    doc_dict = {}\n",
    "    doc_dict['doc_id'] = doc_id\n",
    "    doc_dict['text_tags'] = text_tags\n",
    "    all_text_tag.append(doc_dict)\n",
    "fw = open(\"all_text_tag.json\", \"w\", encoding=\"utf-8\")\n",
    "json.dump(all_text_tag, fw, ensure_ascii=False, indent=4)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259c45b9",
   "metadata": {},
   "source": [
    "# preprocess tags \n",
    "## make them pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b0c8a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import re\n",
    "    regex = re.compile('[^a-zA-Z]') # to remove .1.2.3 and _ in hidden tags\n",
    "\n",
    "    def useful_tag_8(tags: str):\n",
    "        tags = tags.lower()\n",
    "        if \"|\" in tags:\n",
    "            tags = tags.split(\"|\")\n",
    "            ans = []\n",
    "            for tag in tags:\n",
    "                if tag:\n",
    "                    name, tag = tag.split(\"=\")\n",
    "                    taglist = tag.split(\":\")\n",
    "                    regextaglist = [regex.sub(' ', _) for _ in taglist]\n",
    "                    \n",
    "                    alltag = \" \".join(regextaglist)\n",
    "                    ans.append(name + \" : \" + alltag)\n",
    "                    # replace multiple blankspace with one\n",
    "                    newans = [' '.join(_.split()) for _ in ans] \n",
    "            if len(newans) != 0:\n",
    "                return newans\n",
    "            else:\n",
    "                return \"_\"\n",
    "        \n",
    "        else:\n",
    "            ans = []\n",
    "            if tags != '_':\n",
    "                \n",
    "                name, tag = tags.split(\"=\")\n",
    "                taglist = tag.split(\":\")\n",
    "                regextaglist = [regex.sub(' ', _) for _ in taglist]\n",
    "               \n",
    "                alltag = \" \".join(regextaglist)\n",
    "                ans.append(name + \" : \" + alltag)\n",
    "                newans = [' '.join(_.split()) for _ in ans]\n",
    "                if len(newans) != 0:\n",
    "                    return newans\n",
    "            else:\n",
    "                return \"_\"\n",
    "\n",
    "    def part_to_text(partlist:list,text:str): # change part number to the word\n",
    "        text_list = text.split()\n",
    "        for i, _ in enumerate(partlist):\n",
    "            if _ != '_':\n",
    "                partlist[i] = text_list[int(_)-1]\n",
    "        return partlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0928cf",
   "metadata": {},
   "source": [
    "# merge text and tag\n",
    "## in the form: ' text text # TAG = tag # # TAG = tag # text text '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b97ae550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def mergeTextTag(columns:tuple, jsonFile):\n",
    "    \n",
    "    '''\n",
    "    merge text and tags from json file in the form:    \n",
    "    text text # TAG = tag # # TAG = tag # text text .\n",
    "    \n",
    "    parameters: \n",
    "        columns: tuple of str, where the tags are from, tags can from multiple columns\n",
    "        json: str, the input json file address\n",
    "    \n",
    "    input: \n",
    "        column idx in tuple\n",
    "        json data file\n",
    "        \n",
    "    '''\n",
    "    file = json.load(jsonFile)\n",
    "    paddeddata = []\n",
    "    \n",
    "    for each_doc in file:\n",
    "        paddeddoc = {}\n",
    "        paddeddoc['text']=[]\n",
    "        paddeddoc['doc_id']=each_doc['doc_id']\n",
    "        \n",
    "        texttag_list = each_doc['text_tags'] # list\n",
    "        \n",
    "        # allign each word with target columns tags of it\n",
    "        for _ in texttag_list: \n",
    "            tags = _['tagcols'] \n",
    "            text_list = _['text'].split(' ') # the sentence list\n",
    "            \n",
    "            # combine cols of tags together in list.\n",
    "            tags_to_merge = [list(t) for t in zip(tags[c] for c in columns)] \n",
    "            unested = [list(itertools.chain(*sub)) for sub in tags_to_merge]\n",
    "            \n",
    "            # unzip the hidden tag list\n",
    "            for l in unested:\n",
    "                for i, v in enumerate(l):\n",
    "                    if type(v) == list:\n",
    "                        l[i] = ', '.join(v)\n",
    "            \n",
    "            # add '#' at the start and end of tags \n",
    "            newtag = []\n",
    "            for idx, _ in enumerate(zip(*unested)): # add tag name and '#' for not meaningful tags\n",
    "                if not all( l == '_' for l in _ ):\n",
    "                    hashpadlist =['# ' + columns[i] + ' : ' + t + ' # ' \\\n",
    "                                for i, t in enumerate(_) if t != '_']\n",
    "                    hashpad = ' '.join(hashpadlist)\n",
    "                    newtag.append(hashpad)\n",
    "                else:\n",
    "                    newtag.append('')\n",
    "            \n",
    "            paddedtext = ''\n",
    "            # and merge with the text list \n",
    "            \n",
    "            for text, tag in zip(text_list, newtag):\n",
    "                paddedtext += text + ' ' + tag\n",
    "            pt = paddedtext.replace('hidden : ','')\n",
    "            # append padded text to the list\n",
    "            paddeddoc['text'].append(pt)\n",
    "        paddeddata.append(paddeddoc)\n",
    "    return paddeddata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94dea941",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jsonpath = r'/Users/rickzhai/Documents/GitHub/ITNLP_Semeval2022_Task6/number_reasoning/all_text_tag.json'\n",
    "f = open(jsonpath, 'r', encoding='utf-8')\n",
    "padded = mergeTextTag(columns=('part','hidden','coref'), jsonFile=f)\n",
    "w = open(\"padded_text_for_type_0.json\", \"w\", encoding=\"utf-8\")\n",
    "json.dump(padded, w, ensure_ascii=False, indent=4)\n",
    "w.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e35a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
