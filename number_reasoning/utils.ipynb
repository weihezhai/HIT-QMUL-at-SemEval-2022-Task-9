{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01dc5dc3",
   "metadata": {},
   "source": [
    "# extract type 0 data only\n",
    "## and removed answers with magnitude more than 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3424be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def extract_id(start_token='0', filepath=r'alldata.json'):\n",
    "    start = start_token\n",
    "    texts = []\n",
    "    with open(filepath,\"r\",encoding='utf-8') as f:\n",
    "        data=json.load(f)\n",
    "    for key,item in data.items():\n",
    "        questions=item['question']\n",
    "        for q in questions:\n",
    "            q_temp,a=q.split('     ')\n",
    "            idx,q = q_temp.split(\"=\")\n",
    "            idx_=idx.split(\" \")[-2]\n",
    "            if idx_.startswith(start):\n",
    "                text={}\n",
    "                text['q_id']=idx_\n",
    "                text['question']=q.strip()\n",
    "                text['answer']=a\n",
    "                text['doc_id']=key.strip()\n",
    "                texts.append(text)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c816a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract type 0 qa pairs\n",
    "fp = '/Users/rickzhai/Desktop/semeval data/training data/datas_1120.json'\n",
    "t = extract_id(start_token='0', filepath=fp)\n",
    "write = open(\"qa_0_all.json\", \"w\", encoding=\"utf-8\")\n",
    "json.dump(t, write, ensure_ascii=False, indent=4)\n",
    "write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3598867",
   "metadata": {},
   "source": [
    "# create df as type_0 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3544f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "qa = r\"/Users/rickzhai/Documents/GitHub/ITNLP_Semeval2022_Task6/number_reasoning/qa_0_all.json\"\n",
    "recipe = r\"/Users/rickzhai/Documents/GitHub/ITNLP_Semeval2022_Task6/number_reasoning/padded_text_all.json\"\n",
    "with open(qa,\"r\",encoding='utf-8') as f:\n",
    "    qa_0=json.load(f)\n",
    "with open(recipe,\"r\",encoding='utf-8') as f:\n",
    "    c=json.load(f)\n",
    "data = {}\n",
    "data['question'] = []\n",
    "data['answer'] = []\n",
    "data['context'] = []\n",
    "for _ in qa_0:\n",
    "    if _.get('question'):\n",
    "        data['question'].append(_.get('question'))\n",
    "        data['answer'].append(int(_.get('answer')))\n",
    "        docid = _.get('doc_id')\n",
    "        the_doc = next((sub for sub in c if sub['doc_id'] == docid), None)\n",
    "        context = ''.join(the_doc['text'])\n",
    "        data['context'].append(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2612906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ca817",
   "metadata": {},
   "source": [
    "# write to csv for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d541e0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.to_csv('qa_0_all.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "863baace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(str(df.iloc[1821].answer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d8f898c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3306"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9040b3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp38-cp38-macosx_10_6_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 8.5 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.96\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7db3ddbc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ALBERT tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-large-4096-finetuned-triviaqa were not used when initializing LongformerForSequenceClassification: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-large-4096-finetuned-triviaqa and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading ALBERT tokenizer...')\n",
    "l='allenai/longformer-large-4096-finetuned-triviaqa'\n",
    "b='google/bigbird-roberta-large'\n",
    "tokenizer = AutoTokenizer.from_pretrained(l, do_lower_case=True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(l, num_labels=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfc9b765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "outputs = model(**inputs, labels=labels, return_dict = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a3f5192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd86a94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Embedding Layer ====\n",
      "\n",
      "longformer.embeddings.word_embeddings.weight            (50265, 1024)\n",
      "longformer.embeddings.position_embeddings.weight        (4098, 1024)\n",
      "longformer.embeddings.token_type_embeddings.weight         (1, 1024)\n",
      "longformer.embeddings.LayerNorm.weight                       (1024,)\n",
      "longformer.embeddings.LayerNorm.bias                         (1024,)\n",
      "longformer.encoder.layer.0.attention.self.query.weight  (1024, 1024)\n",
      "longformer.encoder.layer.0.attention.self.query.bias         (1024,)\n",
      "longformer.encoder.layer.0.attention.self.key.weight    (1024, 1024)\n",
      "longformer.encoder.layer.0.attention.self.key.bias           (1024,)\n",
      "longformer.encoder.layer.0.attention.self.value.weight  (1024, 1024)\n",
      "longformer.encoder.layer.0.attention.self.value.bias         (1024,)\n",
      "longformer.encoder.layer.0.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.0.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.0.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.0.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.0.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.0.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.0.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.0.attention.output.dense.bias       (1024,)\n",
      "longformer.encoder.layer.0.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.0.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.0.intermediate.dense.weight    (4096, 1024)\n",
      "longformer.encoder.layer.0.intermediate.dense.bias           (4096,)\n",
      "longformer.encoder.layer.0.output.dense.weight          (1024, 4096)\n",
      "longformer.encoder.layer.0.output.dense.bias                 (1024,)\n",
      "longformer.encoder.layer.0.output.LayerNorm.weight           (1024,)\n",
      "longformer.encoder.layer.0.output.LayerNorm.bias             (1024,)\n",
      "longformer.encoder.layer.1.attention.self.query.weight  (1024, 1024)\n",
      "longformer.encoder.layer.1.attention.self.query.bias         (1024,)\n",
      "longformer.encoder.layer.1.attention.self.key.weight    (1024, 1024)\n",
      "longformer.encoder.layer.1.attention.self.key.bias           (1024,)\n",
      "longformer.encoder.layer.1.attention.self.value.weight  (1024, 1024)\n",
      "longformer.encoder.layer.1.attention.self.value.bias         (1024,)\n",
      "longformer.encoder.layer.1.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.1.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.1.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.1.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.1.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.1.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.1.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.1.attention.output.dense.bias       (1024,)\n",
      "longformer.encoder.layer.1.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.1.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.1.intermediate.dense.weight    (4096, 1024)\n",
      "longformer.encoder.layer.1.intermediate.dense.bias           (4096,)\n",
      "longformer.encoder.layer.1.output.dense.weight          (1024, 4096)\n",
      "longformer.encoder.layer.1.output.dense.bias                 (1024,)\n",
      "longformer.encoder.layer.1.output.LayerNorm.weight           (1024,)\n",
      "longformer.encoder.layer.1.output.LayerNorm.bias             (1024,)\n",
      "longformer.encoder.layer.2.attention.self.query.weight  (1024, 1024)\n",
      "longformer.encoder.layer.2.attention.self.query.bias         (1024,)\n",
      "longformer.encoder.layer.2.attention.self.key.weight    (1024, 1024)\n",
      "longformer.encoder.layer.2.attention.self.key.bias           (1024,)\n",
      "longformer.encoder.layer.2.attention.self.value.weight  (1024, 1024)\n",
      "longformer.encoder.layer.2.attention.self.value.bias         (1024,)\n",
      "longformer.encoder.layer.2.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.2.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.2.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.2.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.2.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.2.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.2.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.2.attention.output.dense.bias       (1024,)\n",
      "longformer.encoder.layer.2.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.2.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.2.intermediate.dense.weight    (4096, 1024)\n",
      "longformer.encoder.layer.2.intermediate.dense.bias           (4096,)\n",
      "longformer.encoder.layer.2.output.dense.weight          (1024, 4096)\n",
      "longformer.encoder.layer.2.output.dense.bias                 (1024,)\n",
      "longformer.encoder.layer.2.output.LayerNorm.weight           (1024,)\n",
      "longformer.encoder.layer.2.output.LayerNorm.bias             (1024,)\n",
      "longformer.encoder.layer.3.attention.self.query.weight  (1024, 1024)\n",
      "longformer.encoder.layer.3.attention.self.query.bias         (1024,)\n",
      "longformer.encoder.layer.3.attention.self.key.weight    (1024, 1024)\n",
      "longformer.encoder.layer.3.attention.self.key.bias           (1024,)\n",
      "longformer.encoder.layer.3.attention.self.value.weight  (1024, 1024)\n",
      "longformer.encoder.layer.3.attention.self.value.bias         (1024,)\n",
      "longformer.encoder.layer.3.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.3.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.3.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.3.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.3.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.3.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.3.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.3.attention.output.dense.bias       (1024,)\n",
      "longformer.encoder.layer.3.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.3.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.3.intermediate.dense.weight    (4096, 1024)\n",
      "longformer.encoder.layer.3.intermediate.dense.bias           (4096,)\n",
      "longformer.encoder.layer.3.output.dense.weight          (1024, 4096)\n",
      "longformer.encoder.layer.3.output.dense.bias                 (1024,)\n",
      "longformer.encoder.layer.3.output.LayerNorm.weight           (1024,)\n",
      "longformer.encoder.layer.3.output.LayerNorm.bias             (1024,)\n",
      "longformer.encoder.layer.4.attention.self.query.weight  (1024, 1024)\n",
      "longformer.encoder.layer.4.attention.self.query.bias         (1024,)\n",
      "longformer.encoder.layer.4.attention.self.key.weight    (1024, 1024)\n",
      "longformer.encoder.layer.4.attention.self.key.bias           (1024,)\n",
      "longformer.encoder.layer.4.attention.self.value.weight  (1024, 1024)\n",
      "longformer.encoder.layer.4.attention.self.value.bias         (1024,)\n",
      "longformer.encoder.layer.4.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.4.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.4.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.4.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.4.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.4.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.4.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.4.attention.output.dense.bias       (1024,)\n",
      "longformer.encoder.layer.4.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.4.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.4.intermediate.dense.weight    (4096, 1024)\n",
      "longformer.encoder.layer.4.intermediate.dense.bias           (4096,)\n",
      "longformer.encoder.layer.4.output.dense.weight          (1024, 4096)\n",
      "longformer.encoder.layer.4.output.dense.bias                 (1024,)\n",
      "longformer.encoder.layer.4.output.LayerNorm.weight           (1024,)\n",
      "longformer.encoder.layer.4.output.LayerNorm.bias             (1024,)\n",
      "longformer.encoder.layer.5.attention.self.query.weight  (1024, 1024)\n",
      "longformer.encoder.layer.5.attention.self.query.bias         (1024,)\n",
      "longformer.encoder.layer.5.attention.self.key.weight    (1024, 1024)\n",
      "longformer.encoder.layer.5.attention.self.key.bias           (1024,)\n",
      "longformer.encoder.layer.5.attention.self.value.weight  (1024, 1024)\n",
      "longformer.encoder.layer.5.attention.self.value.bias         (1024,)\n",
      "longformer.encoder.layer.5.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.5.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.5.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.5.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.5.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.5.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.5.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.5.attention.output.dense.bias       (1024,)\n",
      "longformer.encoder.layer.5.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.5.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.5.intermediate.dense.weight    (4096, 1024)\n",
      "longformer.encoder.layer.5.intermediate.dense.bias           (4096,)\n",
      "longformer.encoder.layer.5.output.dense.weight          (1024, 4096)\n",
      "longformer.encoder.layer.5.output.dense.bias                 (1024,)\n",
      "longformer.encoder.layer.5.output.LayerNorm.weight           (1024,)\n",
      "longformer.encoder.layer.5.output.LayerNorm.bias             (1024,)\n",
      "longformer.encoder.layer.6.attention.self.query.weight  (1024, 1024)\n",
      "longformer.encoder.layer.6.attention.self.query.bias         (1024,)\n",
      "longformer.encoder.layer.6.attention.self.key.weight    (1024, 1024)\n",
      "longformer.encoder.layer.6.attention.self.key.bias           (1024,)\n",
      "longformer.encoder.layer.6.attention.self.value.weight  (1024, 1024)\n",
      "longformer.encoder.layer.6.attention.self.value.bias         (1024,)\n",
      "longformer.encoder.layer.6.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.6.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.6.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.6.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.6.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.6.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.6.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.6.attention.output.dense.bias       (1024,)\n",
      "longformer.encoder.layer.6.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.6.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.6.intermediate.dense.weight    (4096, 1024)\n",
      "longformer.encoder.layer.6.intermediate.dense.bias           (4096,)\n",
      "longformer.encoder.layer.6.output.dense.weight          (1024, 4096)\n",
      "longformer.encoder.layer.6.output.dense.bias                 (1024,)\n",
      "longformer.encoder.layer.6.output.LayerNorm.weight           (1024,)\n",
      "longformer.encoder.layer.6.output.LayerNorm.bias             (1024,)\n",
      "longformer.encoder.layer.7.attention.self.query.weight  (1024, 1024)\n",
      "longformer.encoder.layer.7.attention.self.query.bias         (1024,)\n",
      "longformer.encoder.layer.7.attention.self.key.weight    (1024, 1024)\n",
      "longformer.encoder.layer.7.attention.self.key.bias           (1024,)\n",
      "longformer.encoder.layer.7.attention.self.value.weight  (1024, 1024)\n",
      "longformer.encoder.layer.7.attention.self.value.bias         (1024,)\n",
      "longformer.encoder.layer.7.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.7.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.7.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.7.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.7.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.7.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.7.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.7.attention.output.dense.bias       (1024,)\n",
      "longformer.encoder.layer.7.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.7.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.7.intermediate.dense.weight    (4096, 1024)\n",
      "longformer.encoder.layer.7.intermediate.dense.bias           (4096,)\n",
      "longformer.encoder.layer.7.output.dense.weight          (1024, 4096)\n",
      "longformer.encoder.layer.7.output.dense.bias                 (1024,)\n",
      "longformer.encoder.layer.7.output.LayerNorm.weight           (1024,)\n",
      "longformer.encoder.layer.7.output.LayerNorm.bias             (1024,)\n",
      "longformer.encoder.layer.8.attention.self.query.weight  (1024, 1024)\n",
      "longformer.encoder.layer.8.attention.self.query.bias         (1024,)\n",
      "longformer.encoder.layer.8.attention.self.key.weight    (1024, 1024)\n",
      "longformer.encoder.layer.8.attention.self.key.bias           (1024,)\n",
      "longformer.encoder.layer.8.attention.self.value.weight  (1024, 1024)\n",
      "longformer.encoder.layer.8.attention.self.value.bias         (1024,)\n",
      "longformer.encoder.layer.8.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.8.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.8.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.8.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.8.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.8.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.8.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.8.attention.output.dense.bias       (1024,)\n",
      "longformer.encoder.layer.8.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.8.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.8.intermediate.dense.weight    (4096, 1024)\n",
      "longformer.encoder.layer.8.intermediate.dense.bias           (4096,)\n",
      "longformer.encoder.layer.8.output.dense.weight          (1024, 4096)\n",
      "longformer.encoder.layer.8.output.dense.bias                 (1024,)\n",
      "longformer.encoder.layer.8.output.LayerNorm.weight           (1024,)\n",
      "longformer.encoder.layer.8.output.LayerNorm.bias             (1024,)\n",
      "longformer.encoder.layer.9.attention.self.query.weight  (1024, 1024)\n",
      "longformer.encoder.layer.9.attention.self.query.bias         (1024,)\n",
      "longformer.encoder.layer.9.attention.self.key.weight    (1024, 1024)\n",
      "longformer.encoder.layer.9.attention.self.key.bias           (1024,)\n",
      "longformer.encoder.layer.9.attention.self.value.weight  (1024, 1024)\n",
      "longformer.encoder.layer.9.attention.self.value.bias         (1024,)\n",
      "longformer.encoder.layer.9.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.9.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.9.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.9.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.9.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.9.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.9.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.9.attention.output.dense.bias       (1024,)\n",
      "longformer.encoder.layer.9.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.9.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.9.intermediate.dense.weight    (4096, 1024)\n",
      "longformer.encoder.layer.9.intermediate.dense.bias           (4096,)\n",
      "longformer.encoder.layer.9.output.dense.weight          (1024, 4096)\n",
      "longformer.encoder.layer.9.output.dense.bias                 (1024,)\n",
      "longformer.encoder.layer.9.output.LayerNorm.weight           (1024,)\n",
      "longformer.encoder.layer.9.output.LayerNorm.bias             (1024,)\n",
      "longformer.encoder.layer.10.attention.self.query.weight (1024, 1024)\n",
      "longformer.encoder.layer.10.attention.self.query.bias        (1024,)\n",
      "longformer.encoder.layer.10.attention.self.key.weight   (1024, 1024)\n",
      "longformer.encoder.layer.10.attention.self.key.bias          (1024,)\n",
      "longformer.encoder.layer.10.attention.self.value.weight (1024, 1024)\n",
      "longformer.encoder.layer.10.attention.self.value.bias        (1024,)\n",
      "longformer.encoder.layer.10.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.10.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.10.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.10.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.10.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.10.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.10.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.10.attention.output.dense.bias      (1024,)\n",
      "longformer.encoder.layer.10.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.10.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.10.intermediate.dense.weight   (4096, 1024)\n",
      "longformer.encoder.layer.10.intermediate.dense.bias          (4096,)\n",
      "longformer.encoder.layer.10.output.dense.weight         (1024, 4096)\n",
      "longformer.encoder.layer.10.output.dense.bias                (1024,)\n",
      "longformer.encoder.layer.10.output.LayerNorm.weight          (1024,)\n",
      "longformer.encoder.layer.10.output.LayerNorm.bias            (1024,)\n",
      "longformer.encoder.layer.11.attention.self.query.weight (1024, 1024)\n",
      "longformer.encoder.layer.11.attention.self.query.bias        (1024,)\n",
      "longformer.encoder.layer.11.attention.self.key.weight   (1024, 1024)\n",
      "longformer.encoder.layer.11.attention.self.key.bias          (1024,)\n",
      "longformer.encoder.layer.11.attention.self.value.weight (1024, 1024)\n",
      "longformer.encoder.layer.11.attention.self.value.bias        (1024,)\n",
      "longformer.encoder.layer.11.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.11.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.11.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.11.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.11.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.11.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.11.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.11.attention.output.dense.bias      (1024,)\n",
      "longformer.encoder.layer.11.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.11.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.11.intermediate.dense.weight   (4096, 1024)\n",
      "longformer.encoder.layer.11.intermediate.dense.bias          (4096,)\n",
      "longformer.encoder.layer.11.output.dense.weight         (1024, 4096)\n",
      "longformer.encoder.layer.11.output.dense.bias                (1024,)\n",
      "longformer.encoder.layer.11.output.LayerNorm.weight          (1024,)\n",
      "longformer.encoder.layer.11.output.LayerNorm.bias            (1024,)\n",
      "longformer.encoder.layer.12.attention.self.query.weight (1024, 1024)\n",
      "longformer.encoder.layer.12.attention.self.query.bias        (1024,)\n",
      "longformer.encoder.layer.12.attention.self.key.weight   (1024, 1024)\n",
      "longformer.encoder.layer.12.attention.self.key.bias          (1024,)\n",
      "longformer.encoder.layer.12.attention.self.value.weight (1024, 1024)\n",
      "longformer.encoder.layer.12.attention.self.value.bias        (1024,)\n",
      "longformer.encoder.layer.12.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.12.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.12.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.12.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.12.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.12.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.12.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.12.attention.output.dense.bias      (1024,)\n",
      "longformer.encoder.layer.12.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.12.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.12.intermediate.dense.weight   (4096, 1024)\n",
      "longformer.encoder.layer.12.intermediate.dense.bias          (4096,)\n",
      "longformer.encoder.layer.12.output.dense.weight         (1024, 4096)\n",
      "longformer.encoder.layer.12.output.dense.bias                (1024,)\n",
      "longformer.encoder.layer.12.output.LayerNorm.weight          (1024,)\n",
      "longformer.encoder.layer.12.output.LayerNorm.bias            (1024,)\n",
      "longformer.encoder.layer.13.attention.self.query.weight (1024, 1024)\n",
      "longformer.encoder.layer.13.attention.self.query.bias        (1024,)\n",
      "longformer.encoder.layer.13.attention.self.key.weight   (1024, 1024)\n",
      "longformer.encoder.layer.13.attention.self.key.bias          (1024,)\n",
      "longformer.encoder.layer.13.attention.self.value.weight (1024, 1024)\n",
      "longformer.encoder.layer.13.attention.self.value.bias        (1024,)\n",
      "longformer.encoder.layer.13.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.13.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.13.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.13.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.13.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.13.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.13.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.13.attention.output.dense.bias      (1024,)\n",
      "longformer.encoder.layer.13.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.13.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.13.intermediate.dense.weight   (4096, 1024)\n",
      "longformer.encoder.layer.13.intermediate.dense.bias          (4096,)\n",
      "longformer.encoder.layer.13.output.dense.weight         (1024, 4096)\n",
      "longformer.encoder.layer.13.output.dense.bias                (1024,)\n",
      "longformer.encoder.layer.13.output.LayerNorm.weight          (1024,)\n",
      "longformer.encoder.layer.13.output.LayerNorm.bias            (1024,)\n",
      "longformer.encoder.layer.14.attention.self.query.weight (1024, 1024)\n",
      "longformer.encoder.layer.14.attention.self.query.bias        (1024,)\n",
      "longformer.encoder.layer.14.attention.self.key.weight   (1024, 1024)\n",
      "longformer.encoder.layer.14.attention.self.key.bias          (1024,)\n",
      "longformer.encoder.layer.14.attention.self.value.weight (1024, 1024)\n",
      "longformer.encoder.layer.14.attention.self.value.bias        (1024,)\n",
      "longformer.encoder.layer.14.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.14.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.14.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.14.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.14.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.14.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.14.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.14.attention.output.dense.bias      (1024,)\n",
      "longformer.encoder.layer.14.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.14.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.14.intermediate.dense.weight   (4096, 1024)\n",
      "longformer.encoder.layer.14.intermediate.dense.bias          (4096,)\n",
      "longformer.encoder.layer.14.output.dense.weight         (1024, 4096)\n",
      "longformer.encoder.layer.14.output.dense.bias                (1024,)\n",
      "longformer.encoder.layer.14.output.LayerNorm.weight          (1024,)\n",
      "longformer.encoder.layer.14.output.LayerNorm.bias            (1024,)\n",
      "longformer.encoder.layer.15.attention.self.query.weight (1024, 1024)\n",
      "longformer.encoder.layer.15.attention.self.query.bias        (1024,)\n",
      "longformer.encoder.layer.15.attention.self.key.weight   (1024, 1024)\n",
      "longformer.encoder.layer.15.attention.self.key.bias          (1024,)\n",
      "longformer.encoder.layer.15.attention.self.value.weight (1024, 1024)\n",
      "longformer.encoder.layer.15.attention.self.value.bias        (1024,)\n",
      "longformer.encoder.layer.15.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.15.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.15.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.15.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.15.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.15.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.15.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.15.attention.output.dense.bias      (1024,)\n",
      "longformer.encoder.layer.15.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.15.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.15.intermediate.dense.weight   (4096, 1024)\n",
      "longformer.encoder.layer.15.intermediate.dense.bias          (4096,)\n",
      "longformer.encoder.layer.15.output.dense.weight         (1024, 4096)\n",
      "longformer.encoder.layer.15.output.dense.bias                (1024,)\n",
      "longformer.encoder.layer.15.output.LayerNorm.weight          (1024,)\n",
      "longformer.encoder.layer.15.output.LayerNorm.bias            (1024,)\n",
      "longformer.encoder.layer.16.attention.self.query.weight (1024, 1024)\n",
      "longformer.encoder.layer.16.attention.self.query.bias        (1024,)\n",
      "longformer.encoder.layer.16.attention.self.key.weight   (1024, 1024)\n",
      "longformer.encoder.layer.16.attention.self.key.bias          (1024,)\n",
      "longformer.encoder.layer.16.attention.self.value.weight (1024, 1024)\n",
      "longformer.encoder.layer.16.attention.self.value.bias        (1024,)\n",
      "longformer.encoder.layer.16.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.16.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.16.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.16.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.16.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.16.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.16.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.16.attention.output.dense.bias      (1024,)\n",
      "longformer.encoder.layer.16.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.16.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.16.intermediate.dense.weight   (4096, 1024)\n",
      "longformer.encoder.layer.16.intermediate.dense.bias          (4096,)\n",
      "longformer.encoder.layer.16.output.dense.weight         (1024, 4096)\n",
      "longformer.encoder.layer.16.output.dense.bias                (1024,)\n",
      "longformer.encoder.layer.16.output.LayerNorm.weight          (1024,)\n",
      "longformer.encoder.layer.16.output.LayerNorm.bias            (1024,)\n",
      "longformer.encoder.layer.17.attention.self.query.weight (1024, 1024)\n",
      "longformer.encoder.layer.17.attention.self.query.bias        (1024,)\n",
      "longformer.encoder.layer.17.attention.self.key.weight   (1024, 1024)\n",
      "longformer.encoder.layer.17.attention.self.key.bias          (1024,)\n",
      "longformer.encoder.layer.17.attention.self.value.weight (1024, 1024)\n",
      "longformer.encoder.layer.17.attention.self.value.bias        (1024,)\n",
      "longformer.encoder.layer.17.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.17.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.17.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.17.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.17.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.17.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.17.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.17.attention.output.dense.bias      (1024,)\n",
      "longformer.encoder.layer.17.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.17.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.17.intermediate.dense.weight   (4096, 1024)\n",
      "longformer.encoder.layer.17.intermediate.dense.bias          (4096,)\n",
      "longformer.encoder.layer.17.output.dense.weight         (1024, 4096)\n",
      "longformer.encoder.layer.17.output.dense.bias                (1024,)\n",
      "longformer.encoder.layer.17.output.LayerNorm.weight          (1024,)\n",
      "longformer.encoder.layer.17.output.LayerNorm.bias            (1024,)\n",
      "longformer.encoder.layer.18.attention.self.query.weight (1024, 1024)\n",
      "longformer.encoder.layer.18.attention.self.query.bias        (1024,)\n",
      "longformer.encoder.layer.18.attention.self.key.weight   (1024, 1024)\n",
      "longformer.encoder.layer.18.attention.self.key.bias          (1024,)\n",
      "longformer.encoder.layer.18.attention.self.value.weight (1024, 1024)\n",
      "longformer.encoder.layer.18.attention.self.value.bias        (1024,)\n",
      "longformer.encoder.layer.18.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.18.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.18.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.18.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.18.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.18.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.18.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.18.attention.output.dense.bias      (1024,)\n",
      "longformer.encoder.layer.18.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.18.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.18.intermediate.dense.weight   (4096, 1024)\n",
      "longformer.encoder.layer.18.intermediate.dense.bias          (4096,)\n",
      "longformer.encoder.layer.18.output.dense.weight         (1024, 4096)\n",
      "longformer.encoder.layer.18.output.dense.bias                (1024,)\n",
      "longformer.encoder.layer.18.output.LayerNorm.weight          (1024,)\n",
      "longformer.encoder.layer.18.output.LayerNorm.bias            (1024,)\n",
      "longformer.encoder.layer.19.attention.self.query.weight (1024, 1024)\n",
      "longformer.encoder.layer.19.attention.self.query.bias        (1024,)\n",
      "longformer.encoder.layer.19.attention.self.key.weight   (1024, 1024)\n",
      "longformer.encoder.layer.19.attention.self.key.bias          (1024,)\n",
      "longformer.encoder.layer.19.attention.self.value.weight (1024, 1024)\n",
      "longformer.encoder.layer.19.attention.self.value.bias        (1024,)\n",
      "longformer.encoder.layer.19.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.19.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.19.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.19.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.19.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.19.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.19.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.19.attention.output.dense.bias      (1024,)\n",
      "longformer.encoder.layer.19.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.19.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.19.intermediate.dense.weight   (4096, 1024)\n",
      "longformer.encoder.layer.19.intermediate.dense.bias          (4096,)\n",
      "longformer.encoder.layer.19.output.dense.weight         (1024, 4096)\n",
      "longformer.encoder.layer.19.output.dense.bias                (1024,)\n",
      "longformer.encoder.layer.19.output.LayerNorm.weight          (1024,)\n",
      "longformer.encoder.layer.19.output.LayerNorm.bias            (1024,)\n",
      "longformer.encoder.layer.20.attention.self.query.weight (1024, 1024)\n",
      "longformer.encoder.layer.20.attention.self.query.bias        (1024,)\n",
      "longformer.encoder.layer.20.attention.self.key.weight   (1024, 1024)\n",
      "longformer.encoder.layer.20.attention.self.key.bias          (1024,)\n",
      "longformer.encoder.layer.20.attention.self.value.weight (1024, 1024)\n",
      "longformer.encoder.layer.20.attention.self.value.bias        (1024,)\n",
      "longformer.encoder.layer.20.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.20.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.20.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.20.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.20.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.20.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.20.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.20.attention.output.dense.bias      (1024,)\n",
      "longformer.encoder.layer.20.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.20.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.20.intermediate.dense.weight   (4096, 1024)\n",
      "longformer.encoder.layer.20.intermediate.dense.bias          (4096,)\n",
      "longformer.encoder.layer.20.output.dense.weight         (1024, 4096)\n",
      "longformer.encoder.layer.20.output.dense.bias                (1024,)\n",
      "longformer.encoder.layer.20.output.LayerNorm.weight          (1024,)\n",
      "longformer.encoder.layer.20.output.LayerNorm.bias            (1024,)\n",
      "longformer.encoder.layer.21.attention.self.query.weight (1024, 1024)\n",
      "longformer.encoder.layer.21.attention.self.query.bias        (1024,)\n",
      "longformer.encoder.layer.21.attention.self.key.weight   (1024, 1024)\n",
      "longformer.encoder.layer.21.attention.self.key.bias          (1024,)\n",
      "longformer.encoder.layer.21.attention.self.value.weight (1024, 1024)\n",
      "longformer.encoder.layer.21.attention.self.value.bias        (1024,)\n",
      "longformer.encoder.layer.21.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.21.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.21.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.21.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.21.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.21.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.21.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.21.attention.output.dense.bias      (1024,)\n",
      "longformer.encoder.layer.21.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.21.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.21.intermediate.dense.weight   (4096, 1024)\n",
      "longformer.encoder.layer.21.intermediate.dense.bias          (4096,)\n",
      "longformer.encoder.layer.21.output.dense.weight         (1024, 4096)\n",
      "longformer.encoder.layer.21.output.dense.bias                (1024,)\n",
      "longformer.encoder.layer.21.output.LayerNorm.weight          (1024,)\n",
      "longformer.encoder.layer.21.output.LayerNorm.bias            (1024,)\n",
      "longformer.encoder.layer.22.attention.self.query.weight (1024, 1024)\n",
      "longformer.encoder.layer.22.attention.self.query.bias        (1024,)\n",
      "longformer.encoder.layer.22.attention.self.key.weight   (1024, 1024)\n",
      "longformer.encoder.layer.22.attention.self.key.bias          (1024,)\n",
      "longformer.encoder.layer.22.attention.self.value.weight (1024, 1024)\n",
      "longformer.encoder.layer.22.attention.self.value.bias        (1024,)\n",
      "longformer.encoder.layer.22.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.22.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.22.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.22.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.22.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.22.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.22.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.22.attention.output.dense.bias      (1024,)\n",
      "longformer.encoder.layer.22.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.22.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.22.intermediate.dense.weight   (4096, 1024)\n",
      "longformer.encoder.layer.22.intermediate.dense.bias          (4096,)\n",
      "longformer.encoder.layer.22.output.dense.weight         (1024, 4096)\n",
      "longformer.encoder.layer.22.output.dense.bias                (1024,)\n",
      "longformer.encoder.layer.22.output.LayerNorm.weight          (1024,)\n",
      "longformer.encoder.layer.22.output.LayerNorm.bias            (1024,)\n",
      "longformer.encoder.layer.23.attention.self.query.weight (1024, 1024)\n",
      "longformer.encoder.layer.23.attention.self.query.bias        (1024,)\n",
      "longformer.encoder.layer.23.attention.self.key.weight   (1024, 1024)\n",
      "longformer.encoder.layer.23.attention.self.key.bias          (1024,)\n",
      "longformer.encoder.layer.23.attention.self.value.weight (1024, 1024)\n",
      "longformer.encoder.layer.23.attention.self.value.bias        (1024,)\n",
      "longformer.encoder.layer.23.attention.self.query_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.23.attention.self.query_global.bias      (1024,)\n",
      "longformer.encoder.layer.23.attention.self.key_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.23.attention.self.key_global.bias      (1024,)\n",
      "longformer.encoder.layer.23.attention.self.value_global.weight (1024, 1024)\n",
      "longformer.encoder.layer.23.attention.self.value_global.bias      (1024,)\n",
      "longformer.encoder.layer.23.attention.output.dense.weight (1024, 1024)\n",
      "longformer.encoder.layer.23.attention.output.dense.bias      (1024,)\n",
      "longformer.encoder.layer.23.attention.output.LayerNorm.weight      (1024,)\n",
      "longformer.encoder.layer.23.attention.output.LayerNorm.bias      (1024,)\n",
      "longformer.encoder.layer.23.intermediate.dense.weight   (4096, 1024)\n",
      "longformer.encoder.layer.23.intermediate.dense.bias          (4096,)\n",
      "longformer.encoder.layer.23.output.dense.weight         (1024, 4096)\n",
      "longformer.encoder.layer.23.output.dense.bias                (1024,)\n",
      "longformer.encoder.layer.23.output.LayerNorm.weight          (1024,)\n",
      "longformer.encoder.layer.23.output.LayerNorm.bias            (1024,)\n",
      "classifier.dense.weight                                 (1024, 1024)\n",
      "classifier.dense.bias                                        (1024,)\n",
      "classifier.out_proj.weight                                 (3, 1024)\n",
      "classifier.out_proj.bias                                        (3,)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcec816d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  1244\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./qa_0.csv')\n",
    "\n",
    "max_len = 0\n",
    "\n",
    "# For every sentence...\n",
    "for sent in df.context.values:\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53c211fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/rickzhai/opt/anaconda3/lib/python3.8/site-packages (1.10.0)\n",
      "Requirement already satisfied: typing_extensions in /Users/rickzhai/opt/anaconda3/lib/python3.8/site-packages (from torch) (3.7.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8050f7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/rickzhai/opt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "sentences = df.context.values\n",
    "qs = df.question.values\n",
    "# For every sentence...\n",
    "for sent in zip(qs,sentences):\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent[0],\n",
    "                        sent[1],                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                                  # Pad & truncate all sentences.\n",
    "                                   # Pad & truncate all sentences.\n",
    "                        max_length = 1024,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "#labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "#print('Original: ', sentences[0])\n",
    "#print(input_ids[0][:273])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7695204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0,  6179,   171,  2163,   473,    24,   185,     7,   609,     5,\n",
      "        37570,  4884,   116,     2,     2,  8267,   849,   898,  4832, 16639,\n",
      "         8942,     6,  3944,  4832,  7023,   849,     5, 34803,   849,  2731,\n",
      "          506,  4832, 34803,   849,  1437,   849,   233,  4832,   847,   849,\n",
      "           88,  3041,  2816,  1872,   849,  2731,   506,  4832, 16639,  8942,\n",
      "          849,     8,     5, 10114,   849,  2731,   506,  4832, 34803,   849,\n",
      "         1437,   849,   233,  4832,   847,   849,    88, 10970,   111,  1836,\n",
      "         3745,   849,  2731,   506,  4832, 16639,  8942,   849, 25606,   847,\n",
      "          849,  3944,  4832,  7023,   849, 28488,   849,  2731,   506,  4832,\n",
      "        28488,   849,  1437,   849,   233,  4832,   847,   849,     8,   992,\n",
      "         3964, 33764,   849,  2731,   506,  4832,   992,  3964, 33764,   849,\n",
      "         1437,   849,   233,  4832,   847,   849,    88, 35788,   849,  2731,\n",
      "          506,  4832, 16639,  8942,   849,   479,  2241,  4467,   849, 14294,\n",
      "         4832,  5730,   849, 19543,   849,  2731,   506,  4832, 19543,   849,\n",
      "         1437,   849,   233,  4832,  2241,  4467,   849,    11,   132, 25119,\n",
      "            9, 14983,   849,  2731,   506,  4832, 14983,   681,   849,  1437,\n",
      "          849,   233,  4832,  2241,  4467,   849,   681,  2156,  1606,   849,\n",
      "          898,  4832, 14166,  8942,     6, 14294,  4832,  5730,   849, 16639,\n",
      "          849,  2731,   506,  4832, 16639,  8942,   849,  1437,   849,   233,\n",
      "         4832,  1606,   849,  8942,     8,  7142,    13,   158,   728,    81,\n",
      "          614,  2859,  2156, 21881, 10930,   479,    11,    10,  2559,  5730,\n",
      "          849,  2731,   506,  4832,  5730,   849,  1437,   849,   233,  4832,\n",
      "         2241,  4467,   849,  2241,  4467, 37570,   849,  2731,   506,  4832,\n",
      "        37570,  4884,   849,  1437,   849,   233,  4832,  2241,  4467,   849,\n",
      "         4884,  3433,   849,  3944,  4832, 20231,  5571,   849,    24,   849,\n",
      "         2731,   506,  4832,    24,   849,    62,   157,  2156,     8, 14351,\n",
      "          849,  3944,  4832, 20231,  5571,   849,    13,   231,   111,   290,\n",
      "          728,   454,  6219,   196,   479,  1606,     5, 12899,  7456,   849,\n",
      "         2731,   506,  4832, 12899,  7456, 18553,   849,  1437,   849,   233,\n",
      "         4832,  1606,   849, 18553,     7,     5, 14166,   849,  2731,   506,\n",
      "         4832, 14166,  8942,   849,  8942,  2156, 29516,   849,  3944,  4832,\n",
      "        25409,   849,   106,   849,  2731,   506,  4832,   106,   849, 38667,\n",
      "          352,  2156, 14351,   849,  3944,  4832, 25409,   849,     8,  9637,\n",
      "          479,  2937,   849,   898,  4832,  8942,     8, 37570,  4884,   740,\n",
      "        16151,  4104,   849,     5,  4884,   849,  2731,   506,  4832, 37570,\n",
      "         4884,   849,  1437,   849,   233,  4832,  2937,   849,    88,     5,\n",
      "         5730,   849,  2731,   506,  4832,  5730,   849,    19,     5,  8942,\n",
      "          849,  2731,   506,  4832, 14166,  8942,   849,  2156,   191,    19,\n",
      "         6740,   849,  2731,   506,  4832,  6740,   849,  1437,   849,   233,\n",
      "         4832,   191,   849,     8, 10702,   849,  2731,   506,  4832, 10702,\n",
      "          849,  1437,   849,   233,  4832,   191,   849,  2156,  3344, 12826,\n",
      "            7,  9637,    70,  7075,   849,  2731,   506,  4832,  7075,   849,\n",
      "         1437,   849,   233,  4832,  9637,   849,   479,  1807,   849,  1874,\n",
      "         4832,  8942,     8, 37570,  4884,   740, 16151,  4104,   849,    19,\n",
      "        14166,   849,  2731,   506,  4832, 14166,  7666,   849,  1437,   849,\n",
      "          233,  4832,  1807,   849,  7666,    50,   402,  1122,    36, 46411,\n",
      "          438,  1827,   849,  2731,   506,  4832, 46411,   438,  1827,   849,\n",
      "         2156, 35455,   849,  2731,   506,  4832, 35455, 15042,   849, 15042,\n",
      "         4839,   479,  1437,     2,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids[0][:660])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fe205757",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2395 482 178\n",
      "3055\n"
     ]
    }
   ],
   "source": [
    "labels = df.answer.astype(int).values \n",
    "l1 = 0\n",
    "l2 = 0\n",
    "l3 = 0\n",
    "for _ in labels:\n",
    "    if _ == 1:\n",
    "        l1+=1\n",
    "    if _ == 2:\n",
    "        l2+=1\n",
    "    if _ == 3:\n",
    "        l3+=1\n",
    "print(l1,l2,l3)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259c45b9",
   "metadata": {},
   "source": [
    "# preprocess tags \n",
    "## make them pretty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b0c8a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "regex = re.compile('[^a-zA-Z]') # to remove .1.2.3 and _ in hidden tags\n",
    "\n",
    "def useful_tag_8(tags: str):\n",
    "    tags = tags.lower()\n",
    "    if \"|\" in tags:\n",
    "        tags = tags.split(\"|\")\n",
    "        ans = []\n",
    "        for tag in tags:\n",
    "            if tag:\n",
    "                name, tag = tag.split(\"=\")\n",
    "                taglist = tag.split(\":\")\n",
    "                regextaglist = [regex.sub(' ', _) for _ in taglist]\n",
    "\n",
    "                alltag = \" \".join(regextaglist)\n",
    "                ans.append(name + \" : \" + alltag)\n",
    "                # replace multiple blankspace with one\n",
    "                newans = [' '.join(_.split()) for _ in ans] \n",
    "        if len(newans) != 0:\n",
    "            return newans\n",
    "        else:\n",
    "            return \"_\"\n",
    "\n",
    "    else:\n",
    "        ans = []\n",
    "        if tags != '_':\n",
    "\n",
    "            name, tag = tags.split(\"=\")\n",
    "            taglist = tag.split(\":\")\n",
    "            regextaglist = [regex.sub(' ', _) for _ in taglist]\n",
    "\n",
    "            alltag = \" \".join(regextaglist)\n",
    "            ans.append(name + \" : \" + alltag)\n",
    "            newans = [' '.join(_.split()) for _ in ans]\n",
    "            if len(newans) != 0:\n",
    "                return newans\n",
    "        else:\n",
    "            return \"_\"\n",
    "\n",
    "def part_to_text(partlist:list,text:str): # change part number to the word\n",
    "    text_list = text.split()\n",
    "    for i, _ in enumerate(partlist):\n",
    "        if _ != '_':\n",
    "            partlist[i] = text_list[int(_)-1]\n",
    "    return partlist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bfe3c1",
   "metadata": {},
   "source": [
    "# extract text & tag columns.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2cf67e1",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile('[^a-zA-Z]') # to remove .1.2.3 in tags\n",
    "    \n",
    "with open(r\"/Users/rickzhai/Documents/GitHub/ITNLP_Semeval2022_Task6/crl_srl.csv\", 'r', encoding='utf-8') as f:\n",
    "    all_data = f.readlines()\n",
    "all_text_tag = []  # store all text tag columns\n",
    "i = 1\n",
    "while i < 219124:\n",
    "    doc_id = all_data[i - 1].split(\"=\")[1].strip(\"\\n\")  \n",
    "    text_tags = []  \n",
    "    while i < 219124 and 'newdoc id' not in all_data[i]:\n",
    "        item = all_data[i]\n",
    "        if i+1 < 219124:\n",
    "            item_next = all_data[i + 1] \n",
    "        \n",
    "        if 'text =' in item:\n",
    "            item_pre = all_data[i - 1]\n",
    "            if 'ingredients' in item_pre:\n",
    "                i += 1\n",
    "                pass\n",
    "            else:\n",
    "                i += 1\n",
    "                temp_text_tags = {}\n",
    "                texts, tagcols = \"\", {}\n",
    "\n",
    "                tagcols['word'] = []\n",
    "                tagcols['lemma'] = []\n",
    "                tagcols['pos'] = []\n",
    "                tagcols['entity'] = []\n",
    "                tagcols['part'] = []\n",
    "                tagcols['result'] = []\n",
    "                tagcols['hidden'] = []\n",
    "                tagcols['coref'] = []\n",
    "                tagcols['prdct'] = []\n",
    "                tagcols['arg1'] = []\n",
    "                tagcols['arg2'] = []\n",
    "                tagcols['arg3'] = []\n",
    "                tagcols['arg4'] = []\n",
    "                tagcols['arg5'] = []\n",
    "                tagcols['arg6'] = []\n",
    "                tagcols['arg7'] = []\n",
    "                tagcols['arg8'] = []\n",
    "                tagcols['arg9'] = []\n",
    "                tagcols['arg10'] = []\n",
    "                \n",
    "\n",
    "                while i < 219125 and all_data[i] and \"sent_id\" not in all_data[i] and 'newdoc id' not in all_data[i]: \n",
    "                    if \"newpar id\" in all_data[i]:\n",
    "                        i += 1\n",
    "                        continue\n",
    "                    item = all_data[i]\n",
    "\n",
    "                    tags = item.strip().split(\"\\t\")\n",
    "                    if len(tags) != 1:\n",
    "\n",
    "                        tagcols['word'].append(tags[1])\n",
    "                        tagcols['lemma'].append(tags[2])\n",
    "                        tagcols['pos'].append(tags[3])\n",
    "                        tagcols['entity'].append(tags[4])\n",
    "                        tagcols['part'].append(tags[5])\n",
    "                        tagcols['result'].append(tags[6])\n",
    "                        tagcols['hidden'].append(useful_tag_8(tags[7])) # list of hidden tags ['shadow : water', 'habitat : pot']\n",
    "                        if tags[8] != '_':\n",
    "                            tagcols['coref'].append(regex.sub(' ',tags[8]).strip())\n",
    "                        else:\n",
    "                            tagcols['coref'].append(tags[8])\n",
    "                        tagcols['prdct'].append(tags[9])\n",
    "                        tagcols['arg1'].append(tags[10])\n",
    "                        tagcols['arg2'].append(tags[11])\n",
    "                        tagcols['arg3'].append(tags[12])\n",
    "                        tagcols['arg4'].append(tags[13])\n",
    "                        tagcols['arg5'].append(tags[14])\n",
    "                        tagcols['arg6'].append(tags[15])\n",
    "                        tagcols['arg7'].append(tags[16])\n",
    "                        tagcols['arg8'].append(tags[17])\n",
    "                        tagcols['arg9'].append(tags[18])\n",
    "                        tagcols['arg10'].append(tags[19])\n",
    "                        \n",
    "                        texts += (\" \" + tags[1].lower())\n",
    "\n",
    "                    i += 1\n",
    "                temp_text_tags[\"text\"] = texts.strip()\n",
    "                tagcols['part'] = part_to_text(tagcols['part'],temp_text_tags[\"text\"]) # from coref number to the word\n",
    "                temp_text_tags[\"tagcols\"] = tagcols\n",
    "                text_tags.append(temp_text_tags)\n",
    "        else:\n",
    "            i += 1\n",
    "    i += 1\n",
    "\n",
    "    doc_dict = {}\n",
    "    doc_dict['doc_id'] = doc_id\n",
    "    doc_dict['text_tags'] = text_tags\n",
    "    all_text_tag.append(doc_dict)\n",
    "fw = open(\"all_text_tag.json\", \"w\", encoding=\"utf-8\")\n",
    "json.dump(all_text_tag, fw, ensure_ascii=False, indent=4)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b97ae550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def mergeTextTag(columns:tuple, jsonFile):\n",
    "    \n",
    "    '''\n",
    "    merge text and tags from json file in the form:    \n",
    "    text text # TAG = tag # # TAG = tag # text text .\n",
    "    \n",
    "    parameters: \n",
    "        columns: tuple of str, where the tags are from, tags can from multiple columns\n",
    "        json: str, the input json file address\n",
    "    \n",
    "    input: \n",
    "        column idx in tuple\n",
    "        json data file\n",
    "        \n",
    "    '''\n",
    "    file = json.load(jsonFile)\n",
    "    paddeddata = []\n",
    "    \n",
    "    for each_doc in file:\n",
    "        paddeddoc = {}\n",
    "        paddeddoc['text']=[]\n",
    "        paddeddoc['doc_id']=each_doc['doc_id'].strip()\n",
    "        \n",
    "        texttag_list = each_doc['text_tags'] # list\n",
    "        \n",
    "        # allign each word with target columns tags of it\n",
    "        for _ in texttag_list: \n",
    "            tags = _['tagcols'] \n",
    "            text_list = _['text'].split(' ') # the sentence list\n",
    "            \n",
    "            # combine cols of tags together in list.\n",
    "            tags_to_merge = [list(t) for t in zip(tags[c] for c in columns)] \n",
    "            unested = [list(itertools.chain(*sub)) for sub in tags_to_merge]\n",
    "            \n",
    "            # unzip the hidden tag list\n",
    "            for l in unested:\n",
    "                for i, v in enumerate(l):\n",
    "                    if type(v) == list:\n",
    "                        l[i] = ', '.join(v)\n",
    "            \n",
    "            # add '#' at the start and end of tags \n",
    "            newtag = []\n",
    "            for idx, _ in enumerate(zip(*unested)): # add tag name and '#' for not meaningful tags\n",
    "                if not all( l == '_' for l in _ ):\n",
    "                    hashpadlist =['# ' + columns[i] + ' : ' + t + ' # ' \\\n",
    "                                for i, t in enumerate(_) if t != '_']\n",
    "                    hashpad = ' '.join(hashpadlist)\n",
    "                    newtag.append(hashpad)\n",
    "                else:\n",
    "                    newtag.append('')\n",
    "            \n",
    "            paddedtext = ''\n",
    "            # and merge with the text list \n",
    "            \n",
    "            for text, tag in zip(text_list, newtag):\n",
    "                paddedtext += text + ' ' + tag\n",
    "            pt = paddedtext.replace('hidden : ','')\n",
    "            # append padded text to the list\n",
    "            paddeddoc['text'].append(pt)\n",
    "        paddeddata.append(paddeddoc)\n",
    "    return paddeddata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0928cf",
   "metadata": {},
   "source": [
    "# merge text and tag\n",
    "## in the form: ' text text # TAG = tag # # TAG = tag # text text '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94dea941",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "jsonpath = r'/Users/rickzhai/Documents/GitHub/ITNLP_Semeval2022_Task6/number_reasoning/all_text_tag.json'\n",
    "f = open(jsonpath, 'r', encoding='utf-8')\n",
    "padded = mergeTextTag(columns=('coref','part','hidden'), jsonFile=f)\n",
    "w = open(\"padded_text_all.json\", \"w\", encoding=\"utf-8\")\n",
    "json.dump(padded, w, ensure_ascii=False, indent=4)\n",
    "w.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e35a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
