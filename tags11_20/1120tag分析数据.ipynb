{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66db713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def extract2():\n",
    "    '''\n",
    "    从原来的csv提取出问答对json,将原材料单独标注出来\n",
    "    保留了question-id\n",
    "    :return:\n",
    "    '''\n",
    "    with open(r\"E:\\RecipeQA\\data\\数据集\\r2vq_train_10_28_2021\\train\\crl_srl.csv\", 'r', encoding='utf-8') as f:\n",
    "        all_data = f.readlines()\n",
    "    dicts = {}\n",
    "    question = []\n",
    "    text = []\n",
    "    meta = []\n",
    "    ingredients = []\n",
    "    newdoc_id = ''  # 防止报错\n",
    "    for i in range(len(all_data) - 1):\n",
    "        item = all_data[i]\n",
    "        if 'newdoc id' in item:\n",
    "            if i != 0:\n",
    "                dicts[newdoc_id] = {}\n",
    "                dicts[newdoc_id]['question'] = question\n",
    "                # text = \" \".join(text)\n",
    "                dicts[newdoc_id]['text'] = text\n",
    "                dicts[newdoc_id]['meta'] = meta\n",
    "                dicts[newdoc_id]['ingredients'] = ingredients\n",
    "            # 清空--\n",
    "            newdoc_id = item.split(\"=\")[1].strip(\"\\n\")\n",
    "            question = []\n",
    "            text = []\n",
    "            meta = []\n",
    "            ingredients = []\n",
    "            continue\n",
    "        item_next = all_data[i + 1]\n",
    "        if 'question' in item and 'answer' in item_next:\n",
    "            qa = item.strip(\"\\n\") + \"    \" + item_next.split(\"=\")[1].strip(\"\\n\")\n",
    "            question.append(qa)\n",
    "        if 'text =' in item:\n",
    "            item_pre = all_data[i - 1]\n",
    "            if 'ingredients' in item_pre:\n",
    "                ingredients.append(item.split(\"=\")[1].strip(\"\\n\"))\n",
    "            else:\n",
    "                text.append(item.split(\"=\")[1].strip(\"\\n\"))\n",
    "        if 'metadata:url' in item:\n",
    "            meta.append(item.split('/')[-1].strip(\"\\n\"))\n",
    "    fw = open(\"datas_1120.json\", \"w\", encoding=\"utf-8\")\n",
    "    json.dump(dicts, fw, ensure_ascii=False, indent=4)\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f251ce3c",
   "metadata": {},
   "source": [
    "# 取出以某id开始的问题\n",
    "是在extarct()到json文件的基础上提取的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba7f6552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id():\n",
    "    startwith='2'\n",
    "    texts=[]\n",
    "    with open(r\"datas_1120.json\",\"r\",encoding='utf-8') as f:\n",
    "        data=json.load(f)\n",
    "    for key,item in data.items():\n",
    "        questions=item['question']\n",
    "        for ques in questions:\n",
    "            q_temp,a=ques.split('     ')\n",
    "            idx,q = q_temp.split(\"=\")\n",
    "            idx_=idx.split(\" \")[-2]\n",
    "            if idx_.startswith(startwith):\n",
    "                text={}\n",
    "                text['id']=idx_\n",
    "                text['question']=q\n",
    "                text['answer']=a\n",
    "                texts.append(text)\n",
    "    # fw = open(\"start3.json\", \"w\", encoding=\"utf-8\")\n",
    "    # json.dump(texts, fw, ensure_ascii=False, indent=4)\n",
    "    # fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08650f16",
   "metadata": {},
   "source": [
    "# 第2类问题，基本都是第八列的tools或者Habitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a8aae89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"E:\\RecipeQA\\data\\数据集\\r2vq_train_10_28_2021\\train\\crl_srl.csv\", 'r', encoding='utf-8') as f:\n",
    "    all_data = f.readlines()\n",
    "all_data2=[] #存储所有信息\n",
    "i=1\n",
    "while i<(219125):\n",
    "    doc_id = all_data[i-1].split(\"=\")[1].strip(\"\\n\") #获取doc_id\n",
    "    list_2qa=[]   #2代表第二类问题，存储quest和answer\n",
    "    text_tags=[]  #存储食谱句子和标签\n",
    "    while 'newdoc id' not in  all_data[i]:\n",
    "        item = all_data[i]\n",
    "        item_next = all_data[i + 1]\n",
    "        if 'question' in item and 'answer' in item_next:\n",
    "            quest_idx = item.strip().split(\"=\")[0].split(\" \")[-2]\n",
    "            if quest_idx.startswith('2'):\n",
    "                temp_qa={}\n",
    "                quest = item.strip().split(\"=\")[1]\n",
    "                answer = item_next.strip().split(\"=\")[-1]\n",
    "                temp_qa['quest']=quest\n",
    "                temp_qa['answer']=answer\n",
    "                list_2qa.append(temp_qa)\n",
    "            i+=1\n",
    "        elif 'text =' in item:\n",
    "            item_pre = all_data[i - 1]\n",
    "            if 'ingredients' in item_pre:\n",
    "                i+=1\n",
    "                pass\n",
    "            else:\n",
    "                i+=1\n",
    "                temp_text_tags={}\n",
    "                texts,hiddens=\"\",[]\n",
    "                while all_data[i] and \"sent_id\" not in all_data[i] and 'newdoc id' not in all_data[i]: #在数据集的最后一行加了newdoc id\n",
    "                    if \"newpar id\" in all_data[i]:\n",
    "                        i+=1\n",
    "                        continue\n",
    "                    item=all_data[i]\n",
    "                    \n",
    "                    tags = item.strip().split(\"\\t\")\n",
    "                    if len(tags)!=1:\n",
    "                        word = tags[1]\n",
    "                        HIDDEN = tags[7].split(\"|\")[-1]\n",
    "                        texts+=(\" \"+word)\n",
    "                        hiddens.append(HIDDEN)\n",
    "                    i+=1\n",
    "                temp_text_tags[\"text\"]=texts\n",
    "                temp_text_tags[\"tags\"]=hiddens\n",
    "                text_tags.append(temp_text_tags)\n",
    "        else:\n",
    "            i+=1\n",
    "    i+=1\n",
    "    \n",
    "    doc_dict={}\n",
    "    doc_dict['doc_id']=doc_id\n",
    "    doc_dict['list_2qa']=list_2qa\n",
    "    doc_dict['text_tags']=text_tags\n",
    "    all_data2.append(doc_dict)\n",
    "fw = open(\"2_all_data.json\", \"w\", encoding=\"utf-8\")\n",
    "json.dump(all_data2, fw, ensure_ascii=False, indent=4)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ceaf92",
   "metadata": {},
   "source": [
    "# 第3类问题，\n",
    "#分为两种：\n",
    "what's in the <something> 答案在句子里或者第八列的drop下，11列patient可以给予提示\n",
    "how did you get <something> 答案都是“by 动词ing +第八列tool或habitat” \n",
    "但是something一定在第八列的result下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6bce630",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"E:\\RecipeQA\\data\\数据集\\r2vq_train_10_28_2021\\train\\crl_srl.csv\", 'r', encoding='utf-8') as f:\n",
    "    all_data = f.readlines()\n",
    "all_data3=[] #存储所有信息\n",
    "i=1\n",
    "while i<(219125):\n",
    "    doc_id = all_data[i-1].split(\"=\")[1].strip(\"\\n\") #获取doc_id\n",
    "    list_3qa=[]   #2代表第二类问题，存储quest和answer\n",
    "    text_tags=[]  #存储食谱句子和标签\n",
    "    while 'newdoc id' not in  all_data[i]:\n",
    "        item = all_data[i]\n",
    "        item_next = all_data[i + 1]\n",
    "        if 'question' in item and 'answer' in item_next:\n",
    "            quest_idx = item.strip().split(\"=\")[0].split(\" \")[-2]\n",
    "            if quest_idx.startswith('3'):\n",
    "                temp_qa={}\n",
    "                quest = item.strip().split(\"=\")[1]\n",
    "                answer = item_next.strip().split(\"=\")[-1]\n",
    "                temp_qa['quest']=quest\n",
    "                temp_qa['answer']=answer\n",
    "                list_3qa.append(temp_qa)\n",
    "            i+=1\n",
    "        elif 'text =' in item:\n",
    "            item_pre = all_data[i - 1]\n",
    "            if 'ingredients' in item_pre:\n",
    "                i+=1\n",
    "                pass\n",
    "            else:\n",
    "                i+=1\n",
    "                temp_text_tags={}\n",
    "                texts,eight_hiddens,eleve=\"\",[],[]\n",
    "                while all_data[i] and \"sent_id\" not in all_data[i] and 'newdoc id' not in all_data[i]: #在数据集的最后一行加了newdoc id\n",
    "                    if \"newpar id\" in all_data[i]:\n",
    "                        i+=1\n",
    "                        continue\n",
    "                    item=all_data[i]\n",
    "                    \n",
    "                    tags = item.strip().split(\"\\t\")\n",
    "                    if len(tags)!=1:\n",
    "                        word = tags[1]\n",
    "                        HIDDEN = tags[7]\n",
    "                        patient=tags[10]\n",
    "                        texts+=(\" \"+word)\n",
    "                        eight_hiddens.append(HIDDEN)\n",
    "                        eleve.append(patient)\n",
    "                    i+=1\n",
    "                temp_text_tags[\"text\"]=texts\n",
    "                temp_text_tags[\"hidden\"]=eight_hiddens\n",
    "                temp_text_tags[\"patient\"]=eleve\n",
    "                text_tags.append(temp_text_tags)\n",
    "        else:\n",
    "            i+=1\n",
    "    i+=1\n",
    "\n",
    "    doc_dict={}\n",
    "    doc_dict['doc_id']=doc_id\n",
    "    doc_dict['list_2qa']=list_3qa\n",
    "    doc_dict['text_tags']=text_tags\n",
    "    all_data3.append(doc_dict)\n",
    "fw = open(\"3_all_data.json\", \"w\", encoding=\"utf-8\")\n",
    "json.dump(all_data3, fw, ensure_ascii=False, indent=4)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e0dbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
